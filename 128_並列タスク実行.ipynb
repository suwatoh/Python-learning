{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOB4XDlZpPRt0W5MFVthoTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suwatoh/Python-learning/blob/main/128_%E4%B8%A6%E5%88%97%E3%82%BF%E3%82%B9%E3%82%AF%E5%AE%9F%E8%A1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "並列タスク実行\n",
        "=============="
      ],
      "metadata": {
        "id": "enRm31HrFafz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing\n",
        "---------------"
      ],
      "metadata": {
        "id": "aGg9NdJDPXot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準ライブラリの `multiprocessing` は、`threading` モジュールに似た API を使用してプロセスの生成をサポートするパッケージである。マルチプロセスでは GIL の影響を受けないので並列処理が行われ、CPU 資源を最大限に活用できる。"
      ],
      "metadata": {
        "id": "Fb5PYmQdCZVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロセス開始方式 ###"
      ],
      "metadata": {
        "id": "Bnpm1hRzkLPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "現在のプロセスから新たにプロセスを開始するとき、現在のプロセスを**親プロセス**、新たなプロセスを**子プロセス**という。プロセスが新しいタスクを引き受けた時、子プロセスを作成して処理させることができる。\n",
        "\n",
        "`multiprocessing` はプロセスを開始するために以下の方法をサポートしている。\n",
        "\n",
        "  * **fork**: `fork()` というシステムコールを呼び出すことで現在のプロセスをコピーする。プロセスの開始が速いが、プロセスのメモリ空間をそのままコピーするのでメモリ消費量が多い。Unix 系 OS でのみ利用可能。\n",
        "  * **spawn**: 新たに Python インタープリターが動くプロセスを開始する。現在のモジュールは再読み込みされて変数も新たに作り直される。プロセスの開始に時間がかかるが、プログラムが動くのに必要なリソースのみ継承されるのでメモリ消費量を抑えられる。多くのプラットフォームで利用可能。\n",
        "\n",
        "デフォルトの開始方式は、Unix 系 では fork、Windows では spawn。将来的には spawn に統一される予定。現在の開始方式名は `multiprocessing.get_start_method()` 関数で確認できる。開始方式を `method` に設定するには、`multiprocessing.set_start_method(method)` を実行する。これは一度しか呼び出すことができず、その場所もメインモジュールの `if __name__ == '__main__'` 節内で保護された状態でなければならない。"
      ],
      "metadata": {
        "id": "G5N1mnIVkL-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "multiprocessing.get_start_method()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cfx1UAr0qFlv",
        "outputId": "383f0e80-acf2-4984-9d3a-992d3df779f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fork'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### インスタンス化 ###"
      ],
      "metadata": {
        "id": "7D6NKukcPzih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "プロセスを使って子プロセスを作成するには、`multiprocessing.Process` クラスをインスタンス化する。\n",
        "\n",
        "``` python\n",
        "multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)\n",
        "```\n",
        "\n",
        "`multiprocessing.Process` クラスは、`threading.Thread` クラスと同様に使うことができる。ただし、以下のメソッドが加わっている:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `terminate()` | プロセスを強制終了する。finally 句などは実行されないことに注意 | `None` |\n",
        "| `close()` | `Process` オブジェクトを閉じ、関連付けられていたすべてのリソースを開放する。中のプロセスが実行中であった場合、`ValueError` を<br />送出する | `None` |\n",
        "\n",
        "次は、`threading.Thread` のインスタンス化のコード例を `multiprocessing.Process` クラスに書き換えただけである。"
      ],
      "metadata": {
        "id": "5KOVo-d9LTL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "\n",
        "def run():\n",
        "    a = []\n",
        "    for i in range(20000000):\n",
        "        a.append(0)\n",
        "\n",
        "\n",
        "def main(*args):\n",
        "    print(f\"started at {time.strftime('%X')}\")\n",
        "    for t in args:\n",
        "        t.start()\n",
        "    for t in args:\n",
        "        t.join()\n",
        "    print(f\"finished at {time.strftime('%X')}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    t1 = multiprocessing.Process(target=run)\n",
        "    t2 = multiprocessing.Process(target=run)\n",
        "    t3 = multiprocessing.Process(target=run)\n",
        "    print(\"2プロセス-----------\")\n",
        "    main(t1, t2)\n",
        "    print(\"1プロセス-----------\")\n",
        "    main(t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE-K5g4jLhOO",
        "outputId": "f1890167-2bce-4395-8ea2-a39741c5ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2プロセス-----------\n",
            "started at 02:40:04\n",
            "finished at 02:40:08\n",
            "1プロセス-----------\n",
            "started at 02:40:08\n",
            "finished at 02:40:10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードでは、各プロセスが動かす `run()` 関数は CPU バウンドな処理を行う。手元のマシンでこのコードを実行すると、2 個の子プロセスを同時に開始する場合と 1 個の子プロセスを開始する場合で処理にかかる時間がほとんど同じであった。これにより、CPU バウンドな処理でも並列処理されていること、つまり GIL の影響を受けないことがわかる。無料版 Colab では利用できる CPU コア数（論理コア数）が 2 個であるため、Python インタープリターを起動したプロセス（**メインプロセス**という）と子プロセス 1 個しか並列処理できず、2 個の子プロセスは並行処理されることに注意する。\n",
        "\n",
        "``` python\n",
        "multiprocessing.freeze_support()\n",
        "```\n",
        "\n",
        "この関数は、`multiprocessing` を使用しているプログラムをフリーズして Windows の実行可能形式を生成するためのサポートを追加する。サードパーティ製の PyInstaller などで実行可能形式を生成する場合に必要。この関数は、メインモジュールの `if __name__ == '__main__'` の直後に呼び出す必要がある。以下に例を示す:\n",
        "\n",
        "``` python\n",
        "from multiprocessing import Process, freeze_support\n",
        "\n",
        "def f():\n",
        "    print('hello world!')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    Process(target=f).start()\n",
        "```\n",
        "\n",
        "`freeze_support()` の呼び出しは、Unix 系 OS では効果がない。また、Windows の通常の Python インタープリターによって実行されているならば、`freeze_support()` は効果がない。\n",
        "\n",
        "``` python\n",
        "multiprocessing.current_process()\n",
        "```\n",
        "\n",
        "この関数は、現在のプロセスに対応する `Process` オブジェクトを返す。\n",
        "\n",
        "``` python\n",
        "multiprocessing.active_children()\n",
        "```\n",
        "\n",
        "この関数は、現在のすべてのアクティブな子プロセスのリストを返す。\n",
        "\n",
        "``` python\n",
        "multiprocessing.parent_process()\n",
        "```\n",
        "\n",
        "この関数は、現在のプロセスの親プロセスに対応する `Process` オブジェクトを返す。現在のプロセスがメインプロセスの場合、`None` を返す。"
      ],
      "metadata": {
        "id": "3l6HqSmgbH9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, current_process\n",
        "import time\n",
        "\n",
        "def counter(data):\n",
        "    data['n'] += 1\n",
        "    print(f\"{current_process().name}: {data['n']=}\")\n",
        "    time.sleep(0.2)\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    p = Process(target=counter, name='ChildProcess', args=(data,))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print(f\"{current_process().name}: {data['n']=}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbYJvkobKOI",
        "outputId": "bd0a8e87-b919-44d3-c098-7ee12c551d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChildProcess: data['n']=1\n",
            "MainProcess: data['n']=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードでは、子プロセスにおいて辞書 `data` の要素 `data['n']` をインクリメントしているが、その結果がメインプロセスに共有されず、メインプロセスでは `data['n']` は初期値 `0` のままである。fork では子プロセスに `data` のコピーが渡される（spawn では `data` が新たに作り直される）からである。\n",
        "\n",
        "このように、マルチプロセスでは各プロセスが独立したメモリ空間を持つため、他のプロセスの影響を受けずに動作する。これにより、子プロセスの 1 つがクラッシュしても他の子プロセスやメインプロセスは影響を受けず、プログラム全体がダウンするリスクを減らすことができる。"
      ],
      "metadata": {
        "id": "3GNoCtE2d1zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロセスの同期 ###"
      ],
      "metadata": {
        "id": "TodumVhn1Hw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "一般的にマルチプロセスプログラムでは、メモリが共有されないため競合状態が起こらず、マルチスレッドプログラムほどには同期プリミティブを必要としないが、`multiprocessing` は `threading` モジュールと等価な同期プリミティブを備えている。\n",
        "\n",
        "  * `multiprocessing.Lock`\n",
        "  * `multiprocessing.RLock`\n",
        "  * `multiprocessing.Semaphore`\n",
        "  * `multiprocessing.BoundedSemaphore`\n",
        "  * `multiprocessing.Event`\n",
        "  * `multiprocessing.Condition`\n",
        "  * `multiprocessing.Barrier`\n",
        "\n",
        "本来互いに独立しているプロセス間でこうした同期プリミティブが使えるのは、OS の機能を介して特定の一時ファイルにアクセスすることで実現されている。このようにプロセス間でデータのやり取りをする仕組みは**プロセス間通信**（Inter-Process Communication）、略して IPC と呼ばれる。IPC は、共有メモリを利用するだけのスレッド間通信と比べると重い処理となる。\n",
        "\n",
        "次の例では、ロックを使用して、一度に 1 つのプロセスしか標準出力に書き込まないようにしている:"
      ],
      "metadata": {
        "id": "8rTkbbzp1IbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Lock, current_process\n",
        "import time\n",
        "\n",
        "def worker(lock, i):\n",
        "    with lock:\n",
        "        print(f\"{current_process().name}: start\")\n",
        "        time.sleep(0.1)\n",
        "        print(f\"{current_process().name}: end\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lock = Lock()\n",
        "    for num in range(5):\n",
        "        Process(target=worker, name=f\"p{num}\", args=(lock, num)).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQiol__eEbDI",
        "outputId": "1b28bb81-d19b-4575-fb53-442c285045d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p0: start\n",
            "p0: end\n",
            "p1: start\n",
            "p1: end\n",
            "p2: start\n",
            "p2: end\n",
            "p3: start\n",
            "p3: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ロックを使用しないで標準出力に書き込んだ場合は、各プロセスからの出力がごちゃまぜになってしまう。ただし、ロックの範囲ではマルチプロセスの性能を発揮できなくなる。"
      ],
      "metadata": {
        "id": "KVsqq4vlFXsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### パイプとキュー ###"
      ],
      "metadata": {
        "id": "9hvu0we2RINC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**パイプ**（pipe）は、OS が提供する IPC の方式の 1 つであり、2 つのプロセスの入出力をつなぐ。`multiprocessing` は、パイプを利用するための関数 `Pipe` を提供している。\n",
        "\n",
        "``` python\n",
        "multiprocessing.Pipe(duplex=True)\n",
        "```\n",
        "\n",
        "パイプの両端を表すコネクションオブジェクトのペア `(conn1, conn2)` を返す。`conn1` と `conn2` は「接続」した状態となる。`duplex` が `True`（デフォルト）の場合、パイプは双方向性となる。`duplex` が `False` の場合、パイプは一方向性で、`conn1` はデータの受信専用、`conn2` はデータの送信専用になる。\n",
        "\n",
        "コネクションオブジェクトは、以下のメソッドを持つ。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `send(obj)` | 接続している相手にオブジェクトを送る。オブジェクトは `pickle` でシリアライズ可能でなければならない。極端に大きす<br />ぎるオブジェクトでは `ValueError` 例外が送出されることがある。受信専用で `send()` を呼び出すと `OSError` 例外が<br />発生する | `None` |\n",
        "| `recv()` | 接続している相手側から送られたオブジェクトを返す。何か受け取るまで待機する。何も受け取らずに接続が相手側で閉<br />じられた場合 `EOFError` 例外が発生する。送信専用で `recv()` を呼び出すと `OSError` 例外が発生する | Unknown |\n",
        "| `send_bytes(buf,`<br />` offset=0, size=None)` | 接続している相手にバイトデータとして `buf` を送る。`offset` が指定されると `buf` のその位置からデータが読み込まれ<br />る。`size` が指定されると `buf` からその量のデータが読み込まれる。極端に大きすぎるバイトデータでは `ValueError` <br />例外が送出されることがある。受信専用で `send_bytes()` を呼び出すと `OSError` 例外が発生する | `None` |\n",
        "| `recv_bytes([maxlength])` | 接続している相手側から送られたデータをバイト列として返す。何も受け取らずに接続が相手側で閉じられた場合<br /> `EOFError` 例外が発生する。送信専用で `recv_bytes()` を呼び出すと `OSError` 例外が発生する。`maxlength` を指定して<br />いて、かつデータが `maxlength` より長い場合、`OSError` 例外が発生する | `bytes` |\n",
        "| `close()` | 接続を閉じる | `None` |\n",
        "\n",
        "OS による本来のパイプは一方向性であり、双方向性は Python 側の拡張である。2 つのプロセスが同時に同じパイプにデータを入れたり受け取ったりすると、データが破損する可能性がある。このような危険を回避したい場合は、`Pipe(duplex=False)` として通信方向を制限するとよい。\n",
        "\n",
        "`recv()` の処理ではデシリアル化が行われる。それはデータを送ったプロセスが信頼できる場合を除いてセキュリティリスクになることに注意する。これが問題となるなら、バイト列限定となるが `send_bytes()` と `recv_bytes()` を使うとよい。\n",
        "\n",
        "`recv()` や `recv_bytes()` でデータを受け取る順番は、データを送った順番と同じ、つまり先入れ先出し（FIFO）となる。"
      ],
      "metadata": {
        "id": "vySFZO7VRJKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def worker(conn):\n",
        "    conn.send([42, None, 'hello'])\n",
        "    conn.send_bytes(b'thank you')\n",
        "    conn.close()\n",
        "\n",
        "def  main():\n",
        "    parent_conn, child_conn = Pipe()\n",
        "    p = Process(target=worker, args=(child_conn,))\n",
        "    p.start()\n",
        "    assert parent_conn.recv() == [42, None, 'hello']\n",
        "    assert parent_conn.recv_bytes() == b'thank you'\n",
        "    p.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ro7OGM4fadtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "また、 `multiprocessing` は、パイプや 2～3 個のロック/セマフォを使用して実装されたプロセス共有キュー `Queue` も提供している。この `Queue` クラスは `queue.Queue` と同様に使用できるが、`task_done()` と `join()` メソッドがないことに注意。`put()` での例外に `queue.Full`、`get()` での例外に `queue.Empty` が使用されるが、それらは `multiprocessing` の名前空間では利用できないため、これらの例外を捕捉する場合は `queue` からインポートする必要がある。"
      ],
      "metadata": {
        "id": "SutYIe2NfKAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "import time\n",
        "\n",
        "def writer(q):\n",
        "    data = []\n",
        "    data.append([42, None, 'hello'])\n",
        "    data.append(b'thank you')\n",
        "    for msg in data:\n",
        "        q.put(msg)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "def reader(q):\n",
        "    while True:\n",
        "        print(q.get())\n",
        "\n",
        "def main():\n",
        "    q = Queue()\n",
        "    pw = Process(target=writer, args=(q,))\n",
        "    pr = Process(target=reader, args=(q,))\n",
        "    pw.start()\n",
        "    pr.start()\n",
        "    # pwが完了するのを待つ（q.join()はないことに注意）\n",
        "    pw.join()\n",
        "    # prを終了（readerが無限ループなので）\n",
        "    pr.terminate()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94XCcKF1xYSY",
        "outputId": "2b05a694-be91-4243-a685-4145cc09f6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[42, None, 'hello']\n",
            "b'thank you'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 共有オブジェクト ###"
      ],
      "metadata": {
        "id": "Ew43LikOiWCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実は、Unix 系 OS と Windows では、メモリ上の特定の領域を複数のプロセスからアクセス可能とする共有メモリをサポートしている。共有メモリを利用すると、データのシリアル化/デシリアル化を必要とするパイプに比べて、パフォーマンスが大幅に向上する。ただし、以下の点に注意する。\n",
        "\n",
        "  * 共有メモリを使用すると、競合状態がマルチプロセスでも発生することになる。しかも、マルチプロセスでは並列処理が行われるので、共有メモリに対する操作が不可分であること（**アトミック**ともいう）に注意がより必要である。ここにアトミックとは、「操作に途中の状態がなく、一部のみが失敗するということがない」ことである。たとえば、代入演算 `=` はアトミックであるが、`+=` のような演算は読み込みと書き込みを含むためアトミックではない。共有データに対するアトミックでない操作がロックを伴わないと、他のプロセスによる操作が割り込んで、意図しない結果になる可能性がある。\n",
        "  * 共有メモリは OS の機能なので、C のデータ型やデータ構造が利用される。\n",
        "\n",
        "`multiprocessing` は、共有メモリを使用するオブジェクト（**共有オブジェクト**と呼ぶ）をサポートする。次の 2 つの関数は、それぞれ共有メモリに割り当てられた数値と数値の配列を扱う共有オブジェクトを返す。\n",
        "\n",
        "``` python\n",
        "multiprocessing.Value(typecode_or_type, *args, lock=True)\n",
        "multiprocessing.Array(typecode_or_type, size_or_initializer, *, lock=True)\n",
        "```\n",
        "\n",
        "`typecode_or_type` に数値の C データ型を指定する。`ctypes` モジュールで使用できる型か、`array` モジュールで使用されるような 1 文字の型コードを指定できる。\n",
        "\n",
        "キーワード専用引数 `lock` が `True`（デフォルト）なら、値へ同期アクセスするために新たに `RLock` オブジェクトが作成される。\n",
        "\n",
        "`Value()` 関数が返すオブジェクトは、 `value` 属性で値を参照できる。`Array()` 関数が返すオブジェクトは、 `[]` によるインデックス参照で値を参照でき、スライスを使うこともできる。どちらのオブジェクトも、`get_lock()` メソッドで内部ロックオブジェクトにアクセスできる。\n",
        "\n",
        "`Value` と `Array` の使用例:"
      ],
      "metadata": {
        "id": "lTUaXvVj99F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Value, Array\n",
        "\n",
        "\n",
        "def worker(n, a):\n",
        "    # アトミックではない操作はロックを必要とする\n",
        "    with n.get_lock():\n",
        "        n.value += 1\n",
        "\n",
        "        for i in range(len(a)):\n",
        "            a[i] = -a[i]\n",
        "\n",
        "\n",
        "def main():\n",
        "    num = Value(\"i\", 0)\n",
        "    arr = Array(\"d\", [0.1, 0.2, 0.3])\n",
        "\n",
        "    p = Process(target=worker, args=(num, arr))\n",
        "    p.start()\n",
        "    p.join()\n",
        "\n",
        "    print(f\"{num.value = }\")\n",
        "    print(f\"{arr[:] = }\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNRnpdWbgR40",
        "outputId": "438a2812-44cd-4621-b1fc-bd86e72afd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num.value = 1\n",
            "arr[:] = [-0.1, -0.2, -0.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### マネージャー ###"
      ],
      "metadata": {
        "id": "oxx00jVO_RxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**マネージャー**（manager）は、共有オブジェクトの高レベルな使い方をサポートする。マネージャーでは、共有オブジェクトを管理する子プロセスが使用される。このプロセスがサーバープロセスとなって、他のプロセスはサーバープロセスを通して共有オブジェクトにアクセスすることになる。これにより高レベルな使い方ができる反面、サーバープロセスを使うことによるオーバーヘッドが発生すること、IPC にパイプが使われるためデータのシリアル化/デシリアル化によるオーバーヘッドも発生することに注意する。\n",
        "\n",
        "マネージャークラスは、`multiprocessing.managers.BaseManager` クラスの派生クラスとして定義される。`BaseManager` クラスで定義されている主なメソッドは次のとおり。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `start(initializer=None, initargs=())` | サーバープロセスを開始する。`initializer` が `None` でなければ、サーバープロセスは開始時<br />に `initializer(*initargs)` を呼び出す | `None` |\n",
        "| `shutdown()` | サーバープロセスを停止する | `None` |\n",
        "| `get_server()` | マネージャーの制御下にある実際のサーバーを表す `Server` オブジェクトを返す。`Server` オブ<br />ジェクトは `serve_forever()` メソッドを<br />サポートする | `Server` |\n",
        "| `connect()` | ローカルからリモートのマネージャーオブジェクトへ接続する | `None` |\n",
        "| `register(typeid, callable=None,`<br />` proxytype=None, exposed=None,`<br />` method_to_typeid=None,`<br />` create_method=True)` | クラスメソッド。マネージャークラスで呼び出し可能オブジェクトや型を登録するために使用され<br />る | `None` |\n",
        "\n",
        "クラスメソッド `register()` は、「プロキシを返すメソッド」をマネージャークラスに登録するために使用される。**プロキシ**は、共有オブジェクトを参照するオブジェクトであり、自身は組み込み型オブジェクトなどの Python オブジェクトと同様に操作される。プロキシを使うと Python らしい書き方で共有オブジェクトを操作することができる。\n",
        "\n",
        "既に多くの「プロキシを返すメソッド」が登録済みであるマネージャークラス `multiprocessing.managers.SyncManager` が用意されている。これを使えば、プログラマーが `register()` を使ってマネージャークラスを定義する必要がない。ただし、直接インスタンス化するのではなく、次の関数の戻り値としてインスタンスを得ること。\n",
        "\n",
        "``` python\n",
        "multiprocessing.Manager()\n",
        "```\n",
        "\n",
        "「プロキシを返すメソッド」を使用する前に、`start()` メソッドでサーバープロセスを開始しておく必要がある。プロキシを使用する必要がなくなったときは、`shutdown()` でサーバープロセスを停止する。全てのマネージャーは、コンテキストマネージャーとして使用できる。`__enter__()` は `start()` メソッドを呼び出してからマネージャーオブジェクトを返す。また `__exit__()` は `shutdown()` を呼び出す。\n",
        "\n",
        "次のコード片\n",
        "\n",
        "``` python\n",
        "with Manager() as manager:\n",
        "    # do something...\n",
        "```\n",
        "\n",
        "これは、以下と同じ。\n",
        "\n",
        "``` python\n",
        "manager = Manager()\n",
        "manager.start()\n",
        "try:\n",
        "    # do something...\n",
        "finally:\n",
        "    manager.shutdown()\n",
        "```\n",
        "\n",
        "`SyncManager` は、 `dict` や `list`、`multiprocessing.managers.Namespace` などに対応するプロキシを返すメソッドが登録されている。メソッドの名前はそれぞれの型の名前と同じになっている。 `multiprocessing.managers.Namespace` は、ドット演算子 `.` を使用する属性参照で共有オブジェクトを参照するために使用される。\n",
        "\n",
        "`Manager()` の使用例:"
      ],
      "metadata": {
        "id": "gj8gCD6f_SvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "\n",
        "def f(dct, lst, ns):\n",
        "    dct[1] = \"1\"\n",
        "    dct[\"2\"] = 2\n",
        "    dct[0.25] = None\n",
        "    lst.reverse()\n",
        "    ns.x = 10\n",
        "    ns.y = \"hello\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    with Manager() as manager:\n",
        "        dct = manager.dict()\n",
        "        lst = manager.list(range(10))\n",
        "        ns = manager.Namespace()\n",
        "\n",
        "        p = Process(target=f, args=(dct, lst, ns))\n",
        "        p.start()\n",
        "        p.join()\n",
        "\n",
        "        print(f\"{dct=!s}\")\n",
        "        print(f\"{lst=!s}\")\n",
        "        print(f\"{ns.x=}, {ns.y=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPSc9-VhkiGl",
        "outputId": "9a1a64f0-9dbd-412e-b922-2d0b8ed66e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dct={1: '1', '2': 2, 0.25: None}\n",
            "lst=[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
            "ns.x=10, ns.y='hello'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BaseManager` を継承して独自のマネージャーを作成し、それをネットワーク経由で他のコンピューター上のプロセスによって共有することもできる。以下のコード例では、ローカルマシンで実行可能とするため、アドレスを `'localhost'` としている。\n",
        "\n",
        "server.py（共有キューのためにサーバーを作成）:\n",
        "\n",
        "``` python\n",
        "from multiprocessing.managers import BaseManager\n",
        "from queue import Queue\n",
        "\n",
        "queue = Queue()\n",
        "\n",
        "class QueueManager(BaseManager):\n",
        "  pass\n",
        "\n",
        "# キューに対応するプロキシを返すメソッド get_queue を登録\n",
        "QueueManager.register('get_queue', callable=lambda: queue)\n",
        "\n",
        "# マネージャーを取得\n",
        "manager = QueueManager(address=('localhost', 50000), authkey=b'abracadabra')\n",
        "# サーバーを取得\n",
        "server = manager.get_server()\n",
        "# サーバーを起動する\n",
        "server.serve_forever()\n",
        "```\n",
        "\n",
        "client1.py（データをキューに登録）:\n",
        "\n",
        "``` python\n",
        "from multiprocessing.managers import BaseManager\n",
        "\n",
        "class QueueManager(BaseManager):\n",
        "    pass\n",
        "\n",
        "# メソッド get_queue を登録\n",
        "QueueManager.register('get_queue')\n",
        "\n",
        "# マネージャーを取得\n",
        "manager = QueueManager(address=('localhost', 50000), authkey=b'abracadabra')\n",
        "# サーバーへ接続\n",
        "manager.connect()\n",
        "queue = manager.get_queue()\n",
        "queue.put('hello')\n",
        "```\n",
        "\n",
        "client2.py（データをキューから取り出す）:\n",
        "\n",
        "``` python\n",
        "from multiprocessing.managers import BaseManager\n",
        "\n",
        "class QueueManager(BaseManager):\n",
        "    pass\n",
        "\n",
        "# メソッド get_queue を登録\n",
        "QueueManager.register('get_queue')\n",
        "\n",
        "# マネージャーを取得\n",
        "manager = QueueManager(address=('localhost', 50000), authkey=b'abracadabra')\n",
        "# サーバーへ接続\n",
        "manager.connect()\n",
        "queue = manager.get_queue()\n",
        "print(queue.get())\n",
        "```\n",
        "\n",
        "ターミナルを 3 つ起動し、まず 1 つのターミナルで `python server.py` を実行してサーバーを立ち上げ、残りのターミナルでそれぞれ `python client1.py` と `python client2.py` を実行する。`client2.py` のプロセスはキューに値がない場合は待ち状態になり、`client1.py` のプロセスで `'hello'` が put されたら、それを出力する。"
      ],
      "metadata": {
        "id": "WQiE1pd7WGnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 共有メモリ管理 ###"
      ],
      "metadata": {
        "id": "Sf0b92I0AkMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "共有オブジェクトを介して共有メモリを利用できるのであるが、直接に共有メモリそのものを管理することもできる。共有メモリを直接管理することによって、マネージャーを利用しなくても柔軟に共有メモリを利用することができる。\n",
        "\n",
        "`multiprocessing.shared_memory` モジュールは、共有メモリそのものを管理するための `SharedMemory` クラスを提供する。\n",
        "\n",
        "``` python\n",
        "multiprocessing.shared_memory.SharedMemory(name=None, create=False, size=0)\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `name` | 共有メモリの一意の名前を文字列で指定する。`None`（デフォルト）の場合、新しい名前が構成される |\n",
        "| `create` | `True` の場合、新しい共有メモリの領域を確保して、それに結び付いたインスタンスを作成する。`False`（デフォルト）の場合、既存の共有メモリに結び付い<br />たインスタンスを作成する |\n",
        "| `size` | 新しい共有メモリの領域を確保するときに要求されるバイト数。実際に確保されるサイズはこれより大きくなることがある。既存の共有メモリを使用する<br />場合は、`size` は無視される |\n",
        "\n",
        "コンストラクタの `name` と `create` 引数を使うことで、あるプロセスが特定の名前で共有メモリを作成し、別のプロセスが同じ名前を使用して同じ共有メモリを参照することができる。\n",
        "\n",
        "| 属性 | 意味 |\n",
        "|:---|:---|\n",
        "| `buf` | 共有メモリの内容 |\n",
        "| `name` | 読み取り専用。共有メモリの名前（文字列） |\n",
        "| `size` | 読み取り専用。実際に割り当てられた共有メモリのサイズ |\n",
        "\n",
        "`buf` のデータ構造は C の配列であり、オブジェクトの参照ではなくオブジェクトの値そのものが格納される。インデックス参照が可能で、スライスも使える。たとえば、`buf[:4]` は先頭から 4 バイトのデータを参照する。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `close()` | このインスタンスから共有メモリへのアクセスを閉じる。`close()` を呼び出しても共有メモリ領域自体は破棄されない | `None` |\n",
        "| `unlink()` | OS に共有メモリの破棄を要求する。このメソッドは全てのインスタンスのうちいずれかが 1 回だけ呼び出すこと。`unlink()` と `close()` は<br />どちらの順序でも呼び出すことができる | `None` |\n",
        "\n",
        "共有メモリがどのプロセスでも必要なくなった場合は、適切なクリーンアップが実行されるために `unlink()` メソッドを呼び出す必要がある。OS は、共有メモリがどのプロセスからもアクセスされる可能性がないことを確認してから共有メモリを破棄する。このため、全てのインスタンスは共有メモリが不要になったら `close()` を呼び出す必要がある。\n",
        "\n",
        "`SharedMemory` の使用例:"
      ],
      "metadata": {
        "id": "xbvlDhGDz2Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "from multiprocessing import Process, current_process\n",
        "from multiprocessing.shared_memory import SharedMemory\n",
        "\n",
        "\n",
        "def worker(name: str):\n",
        "    # 共有メモリを構成（既存の共有メモリを使用）\n",
        "    shm = SharedMemory(name=name)\n",
        "    print(\"{}: {}, {}, {}, {}\".format(current_process().name, *shm.buf[:4]))\n",
        "    shm.buf[:6] = b\"Python\"\n",
        "\n",
        "    #  共有メモリが不要になったら閉じる\n",
        "    shm.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 共有メモリを構成\n",
        "    shm = SharedMemory(create=True, size=10)\n",
        "    print(f\"Size of SharedMemor: {shm.size}\")\n",
        "    shm.buf[:3] = array.array(\"B\", [11, 22, 33])\n",
        "    shm.buf[3] = 44\n",
        "    assert (shm.buf[0], shm.buf[1], shm.buf[2], shm.buf[3]) == (11, 22, 33, 44)\n",
        "\n",
        "    p = Process(target=worker, name=\"ChildProcess\", args=(shm.name,))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    assert (shm.buf[0], shm.buf[1], shm.buf[2], shm.buf[3]) == (80, 121, 116, 104)\n",
        "    print(\"{}: {}\".format(current_process().name, bytes(shm.buf[:6])))\n",
        "\n",
        "    #  共有メモリが不要になったら閉じる\n",
        "    shm.close()\n",
        "\n",
        "    # 共有メモリを破棄\n",
        "    shm.unlink()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_scFJd4zB7Vf",
        "outputId": "44409a29-aed6-4994-b297-30b0086bd117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of SharedMemor: 10\n",
            "ChildProcess: 11, 22, 33, 44\n",
            "MainProcess: b'Python'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "バイト単位で共有メモリを構成する場合、データサイズが 2 バイト以上のデータ型（例: `float`）を扱うことが難しい。そこで、`multiprocessing.shared_memory` モジュールは、Python の組み込みデータ型からなる固定長リストの形で共有メモリを構成するための `ShareableList` クラスを提供する。`ShareableList` は `SharedMemory` のラッパークラスになっている。\n",
        "\n",
        "``` python\n",
        "multiprocessing.shared_memory.ShareableList(sequence=None, *, name=None)\n",
        "```\n",
        "\n",
        "`sequence` で与えた順番で値が格納された共有メモリ（`name` で一意の名前を付けられる）に結び付けられたオブジェクトを作成する。格納可能な値は次の組み込みデータ型に制限される。\n",
        "\n",
        "  * `int` （ただし符号付き 64 ビット整数）\n",
        "  * `float`\n",
        "  * `bool`\n",
        "  * `str` （ただし UTF-8 エンコードしたとき 10 MB 未満のもの）\n",
        "  * `bytes` （ただし 10 MB 未満のもの）\n",
        "  * `None`\n",
        "\n",
        "既存の `ShareableList` に結び付ける場合は、`sequence` を `None` に設定したまま、`name` で共有メモリの一意の名前を指定する。\n",
        "\n",
        "| 属性 | 意味 |\n",
        "|:---|:---|\n",
        "| `shm` | 内部で作成された `SharedMemory` インスタンス。`close()` や `unlink()` を呼び出すために使われる |\n",
        "\n",
        "`ShareableList` オブジェクトは変更可能なリストのように使える（イテラブルであり、`[]` を使ったインデックス参照も可能）。しかし、全体の長さを変更することはできない（つまり、`append()`、`insert()` などを使用できない）。また、スライスによる新しい `ShareableList` インスタンスの動的な作成をサポートしていない。\n",
        "\n",
        "`str` や `bytes` の値を参照する場合、末尾の連続した `\\x00`（ヌル文字またはヌルバイト）は削除される。`str` や `bytes` の値を変更する場合、もとの値より短い値に変更するのであれば末尾が `\\x00` で埋められるが、もとの値より長い値に変更しようとすれば `ValueError` が発生する。あらかじめ必要な文字数（バイト数）を確保するために末尾に連続した `\\x00` を入れるとよい。ただし、現在、`ShareableList` のバグにより、`sequence` の末尾以外の位置に `\\x00` で埋めた `str` や `bytes` の値を指定した場合に、その値をインデックス参照すると、`\\x00` と一緒に後ろに格納された値も削除されてしまう。このため、`\\x00` で埋めた `str` や `bytes` の値は `sequence` の末尾に置くとよい。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `count(value)` | `value` の出現回数を返す | `int` |\n",
        "| `index(value)` | `value` の最初のインデックス位置を返す。値が存在しない場合は `ValueError` を発生させる | `int` |\n",
        "\n",
        "`ShareableList` の使用例:"
      ],
      "metadata": {
        "id": "HmcxAdZwQsZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, current_process\n",
        "from multiprocessing.shared_memory import ShareableList\n",
        "\n",
        "\n",
        "def worker(name: str):\n",
        "    # 共有メモリを構成（既存の共有メモリを使用）\n",
        "    a = ShareableList(name=name)\n",
        "    print(\"{}: {}, {}, {}, {}, {}\".format(current_process().name, a[0], a[1], a[2], a[3], a[4]))\n",
        "\n",
        "    # データを変更\n",
        "    a[0] = 0\n",
        "    a[1] = 3.141592\n",
        "    a[2] = False\n",
        "    a[3] = b\"aaa\"\n",
        "    a[4] = \"Hello World\"\n",
        "\n",
        "    #  共有メモリが不要になったら閉じる\n",
        "    a.shm.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 共有メモリを構成\n",
        "    a = ShareableList([100, -273.154, True, b\"aaabbb\", \"Hello\\x00\\x00\\x00\\x00\\x00\\x00\"])\n",
        "    assert a.count(100) == 1\n",
        "    assert a.index(True) == 2\n",
        "\n",
        "    p = Process(target=worker, name=\"ChildProcess\", args=(a.shm.name,))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print(\"{}: {}, {}, {}, {}, {}\".format(current_process().name, a[0], a[1], a[2], a[3], a[4]))\n",
        "\n",
        "    #  共有メモリが不要になったら閉じる\n",
        "    a.shm.close()\n",
        "\n",
        "    # 共有メモリを破棄\n",
        "    a.shm.unlink()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trXahe7wvrAa",
        "outputId": "995e2773-9aac-48ae-ee97-60827ca17516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChildProcess: 100, -273.154, True, b'aaabbb', Hello\n",
            "MainProcess: 0, 3.141592, False, b'aaa', Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`unlink()` 忘れを回避するために、マネージャーを使うことができる。`multiprocessing.managers.SharedMemoryManager` はマネージャーで、`start()` メソッドでサーバープロセスを開始してから以下のメソッドで `SharedMemory` や `ShareableList` のインスタンスを作成することができ、また、`shutdown()` メソッドで `unlink()` を呼び出す。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `SharedMemory(size)` | `size` バイトの大きさを要求する新しい `SharedMemory` インスタンスを作成して返す | `SharedMemory` |\n",
        "| `ShareableList(sequence)` | `sequence` の値で初期化された新しい `ShareableList` インスタンスを作成して返す | `ShareableList` |\n",
        "\n",
        "`SharedMemoryManager` をコンテキストマネージャーとして with 文で使用する場合、`start()` と `shutdown()` が暗黙的に実行される。\n",
        "\n",
        "次のコードは、`ShareableList` の使用例を `SharedMemoryManager` を利用する形で書き換える例である。"
      ],
      "metadata": {
        "id": "SlT8IMi12gHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, current_process\n",
        "from multiprocessing.managers import SharedMemoryManager\n",
        "\n",
        "\n",
        "def worker(sl):\n",
        "    print(\"{}: {}, {}, {}, {}, {}\".format(current_process().name, sl[0], sl[1], sl[2], sl[3], sl[4]))\n",
        "\n",
        "    # データを変更\n",
        "    sl[0] = 0\n",
        "    sl[1] = 3.141592\n",
        "    sl[2] = False\n",
        "    sl[3] = b\"aaa\"\n",
        "    sl[4] = \"Hello World\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 共有メモリ管理プロセスを開始\n",
        "    with SharedMemoryManager() as smm:\n",
        "        sl = smm.ShareableList([100, -273.154, True, b\"aaabbb\", \"Hello\\x00\\x00\\x00\\x00\\x00\\x00\"])\n",
        "        assert sl.count(100) == 1\n",
        "        assert sl.index(True) == 2\n",
        "\n",
        "        p = Process(target=worker, name=\"ChildProcess\", args=(sl,))\n",
        "        p.start()\n",
        "        p.join()\n",
        "        print(\"{}: {}, {}, {}, {}, {}\".format(current_process().name, sl[0], sl[1], sl[2], sl[3], sl[4]))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QkJPbX42hE6",
        "outputId": "45d66ebb-9a63-4570-f1ce-cfe6788b4007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChildProcess: 100, -273.154, True, b'aaabbb', Hello\n",
            "MainProcess: 0, 3.141592, False, b'aaa', Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロセスプール ###"
      ],
      "metadata": {
        "id": "YyIyxbv0bI_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "子プロセスの作成は重い処理となるため、少ない子プロセスを使い回す仕組み、いわれる**プロセスプール**を利用すべきである。`multiprocessing` パッケージはプロセスプールを作成するためのクラス `Pool` を提供する。\n",
        "\n",
        "``` python\n",
        "multiprocessing.Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None)\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `processes` | プールされる子プロセスの数。省略した場合、`os.cpu_count()` によって返される数が使用される |\n",
        "| `initializer`,<br /> `initargs` | `initializer` が `None` ではない場合、各子プロセスは開始時に `initializer(*initargs)` を呼び出す |\n",
        "| `maxtasksperchild` | タスクが完了したら終了してもよい子プロセスの数。省略した場合、プロセスがプールと同じ期間だけ生き続ける |\n",
        "\n",
        "`Pool` インスタンスのメソッドは次のとおり。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `apply(func, args=(), kwds={})` | プール内の 1 つの子プロセスを使って、引数 `args` とキーワード引数 `kwds` を伴って `func` を呼<br />ぶ。このメソッドは、終了するまで後続の処理をブロックする | `func` の戻り値 |\n",
        "| `apply_async(func, args=(), kwds={},`<br />` callback=None, error_callback=None)` | `apply()` の非同期版で、`multiprocessing.pool.ApplyResult` クラスのインスタンス（結果オブ<br />ジェクト）を返す。`callback` と `error_callback` には 1 個の引数を受け取る呼び出し可能オブ<br />ジェクトを指定できる。結果を返せるようになったときに `callback` が結果オブジェクトに対して<br />適用される。ただし呼び出しが失敗した場合は、例外インスタンスを伴って `error_callback` が<br />適用される | `ApplyResult` |\n",
        "| `map(func, iterable, chunksize=None)` | 組み込み関数 `map()` の並列版。ただし、`iterable` 引数は 1 つだけサポートされる（`func` の引<br />数は 1 つだけサポートされるということである）。`iterable` から `chunksize `の長さ分だけタス<br />クが切り出されて各プロセスに割り振られる。デフォルトでは、プールされるプロセス数の 4 倍で<br />切り出される | `func` の戻り値<br />のリスト |\n",
        "| `map_async(func, iterable, chunksize=None,`<br />` callback=None, error_callback=None`) | `map()` メソッドの非同期版。`multiprocessing.pool.MapResult` クラスのインスタンス（結果オブ<br />ジェクト）を返す。`callback` と `error_callback` については `apply_async()` と同様 | `MapResult` |\n",
        "| `imap(func, iterable, chunksize=1)` | `map()` の遅延評価版。`func` の戻り値を yield するイテレーターを返す。`chunksize` のデフォルト<br />値は 1 とされる | イテレーター |\n",
        "| `imap_unordered(func, iterable,`<br />` chunksize=1)` | イテレーターが返す結果の順番が任意の順番でよいと見なされることを除けば `imap()` と同じ | イテレーター |\n",
        "| `starmap(self, func, iterable,`<br />` chunksize=None)` | `iterable` の要素が引数としてアンパックされるイテレート可能オブジェクトであると期待される<br />以外は `map()` メソッドと同様。そのため、`iterable` が `[(1,2), (3, 4)]` なら、結果は<br /> `[func(1,2), func(3,4)]` になる | `func` の戻り値<br />のリスト |\n",
        "| `starmap_async(self, func, iterable,`<br />` chunksize=None, callback=None,`<br />` error_callback=None)` | `starmap()` メソッドの非同期版。引数と戻り値は `map_async()` と同様 | `MapResult` |\n",
        "| `close()` | これ以上プールでタスクが実行されないようにする。すべてのタスクが完了した後で子プロセス<br />が終了する | `None` |\n",
        "| `terminate()` | 実行中の処理を完了させずに子プロセスをすぐに停止する | `None` |\n",
        "| `join()` | 子プロセスが終了するのを待つ。`join()` を使用する前に `close()` か `terminate()` を呼び出<br />す必要がある | `None` |\n",
        "\n",
        "`Pool` オブジェクトはコンテキストマネージャーとして使用できる。`__enter__()` は `Pool` オブジェクトを返す。また `__exit__()` は `terminate()` を呼び出す。\n",
        "\n",
        "次のコードは、`apply()` メソッドの使用例である:"
      ],
      "metadata": {
        "id": "7NSPMeRrIOdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool, current_process\n",
        "from random import random\n",
        "import time\n",
        "\n",
        "def worker(x):\n",
        "    print(\"{}(x={}) working...\".format(current_process().name, x))\n",
        "    time.sleep(random())\n",
        "    return x * x\n",
        "\n",
        "def main():\n",
        "    # 同時に最大2個の子プロセス\n",
        "    with Pool(processes=2) as pool:\n",
        "        results = []\n",
        "        for i in range(10):\n",
        "            res = pool.apply(func=worker, args=(i,))\n",
        "            results.append(res)\n",
        "        print(results)\n",
        "    pool.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvy-f1IjCq9m",
        "outputId": "79fb6c82-c23c-4d3a-d222-91d52f54ba2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForkPoolWorker-20(x=0) working...\n",
            "ForkPoolWorker-21(x=1) working...\n",
            "ForkPoolWorker-20(x=2) working...\n",
            "ForkPoolWorker-21(x=3) working...\n",
            "ForkPoolWorker-20(x=4) working...\n",
            "ForkPoolWorker-21(x=5) working...\n",
            "ForkPoolWorker-20(x=6) working...\n",
            "ForkPoolWorker-21(x=7) working...\n",
            "ForkPoolWorker-20(x=8) working...\n",
            "ForkPoolWorker-21(x=9) working...\n",
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`apply()` で指定した `worker()` 関数は `random()` 関数で処理時間が異なるようにしている。それにもかかわらず、出力結果から、2 つの子プロセスが交互に結果を返していること、つまり `apply()` が同期処理を行うことがわかる。マルチプロセスの並列処理には `apply_async()` のほうが適している。`apply()` は、処理の順序付けをしたい場合に使う。\n",
        "\n",
        "`apply_async()` で返される `ApplyResult` オブジェクトは、以下のメソッドを持つ。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `get([timeout])` | 結果を返すが、結果を受け取るまで待ち、結果を受け取ったときに返す。引数に `timeout` を指定すると、結果が `timeout` 秒以内<br />に受け取れない場合に `multiprocessing.TimeoutError` が発生する | 呼び出し<br />の結果 |\n",
        "| `wait([timeout])` | その結果が有効になるか timeout 秒経つまで待つ | `None` |\n",
        "| `ready()` | その呼び出しが完了しているかどうかを返す | `bool` |\n",
        "| `successful()` | その呼び出しが例外を発生させることなく完了したかどうかを返す。その結果が返せる状態でない場合 `ValueError` が発生する | `bool` |\n",
        "\n",
        "次のコードは、`apply_async()` メソッドの使用例である:"
      ],
      "metadata": {
        "id": "BaFhb_riG0Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool, current_process\n",
        "from random import random\n",
        "import time\n",
        "\n",
        "def worker(x):\n",
        "    print(\"{}(x={}) working...\".format(current_process().name, x))\n",
        "    time.sleep(random())\n",
        "    return x * x\n",
        "\n",
        "def main():\n",
        "    # 同時に最大2個の子プロセス\n",
        "    with Pool(processes=2) as pool:\n",
        "        results = []\n",
        "        for i in range(10):\n",
        "            res = pool.apply_async(func=worker, args=(i,))\n",
        "            results.append(res)\n",
        "        # 結果の取得\n",
        "        reply = []\n",
        "        for res in results:\n",
        "            try:\n",
        "                reply.append(res.get(timeout=2.0))\n",
        "            except TimeoutError:\n",
        "                print(\"タイムアウトしました\")\n",
        "    pool.join()\n",
        "    print(reply)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLS6b69IXEqi",
        "outputId": "ae75ef95-d060-4baf-976f-2fdb27580ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForkPoolWorker-22(x=0) working...ForkPoolWorker-23(x=1) working...\n",
            "\n",
            "ForkPoolWorker-22(x=2) working...\n",
            "ForkPoolWorker-23(x=3) working...\n",
            "ForkPoolWorker-23(x=4) working...\n",
            "ForkPoolWorker-22(x=5) working...\n",
            "ForkPoolWorker-22(x=6) working...\n",
            "ForkPoolWorker-22(x=7) working...\n",
            "ForkPoolWorker-23(x=8) working...\n",
            "ForkPoolWorker-22(x=9) working...\n",
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`apply_async()` で指定したタスクは、先にタスクを完了した子プロセスに次々に割り振られていく様子がわかる。また、`ApplyResult` オブジェクトの `get()` メソッドが結果を受け取るまで待つので、順番通りに結果を取得できることもわかる。\n",
        "\n",
        "`apply()` メソッドの使用例と `apply_async()` メソッドの使用例では、子プロセスで動かす関数が 1 引数なので、for 文で繰り返している部分を、それぞれ `map()` メソッドと `map_async()` メソッドで書き換えることができる。`map_async()` で返される `MapResult` オブジェクトは、 `ApplyResult` のサブクラスで、 `get()` メソッドが結果のリストを返すようにオーバーライドされる。\n",
        "\n",
        "次のコードは、`map_async()` メソッドの使用例である:"
      ],
      "metadata": {
        "id": "uIN2htdZSJ6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool, current_process\n",
        "from random import random\n",
        "import time\n",
        "\n",
        "def worker(x):\n",
        "    print(\"{}(x={}) working...\".format(current_process().name, x))\n",
        "    time.sleep(random())\n",
        "    return x * x\n",
        "\n",
        "def main():\n",
        "    # 同時に最大2個の子プロセス\n",
        "    with Pool(processes=2) as pool:\n",
        "        results = pool.map_async(func=worker, iterable=range(10))\n",
        "        # 結果の取得\n",
        "        try:\n",
        "            reply = results.get(timeout=5.0)\n",
        "        except TimeoutError:\n",
        "            print(\"タイムアウトしました\")\n",
        "    pool.join()\n",
        "    print(reply)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrlLyfXPSK_R",
        "outputId": "de7e1b32-9745-49c3-8394-8023c01e6feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForkPoolWorker-24(x=0) working...\n",
            "ForkPoolWorker-25(x=2) working...\n",
            "ForkPoolWorker-24(x=1) working...\n",
            "ForkPoolWorker-25(x=3) working...\n",
            "ForkPoolWorker-24(x=4) working...\n",
            "ForkPoolWorker-24(x=5) working...\n",
            "ForkPoolWorker-25(x=6) working...\n",
            "ForkPoolWorker-25(x=7) working...\n",
            "ForkPoolWorker-24(x=8) working...\n",
            "ForkPoolWorker-24(x=9) working...\n",
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### multiprocessing.dummy ###"
      ],
      "metadata": {
        "id": "RctIhV97YMjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`multiprocessing.dummy` サブパッケージを利用すると、 `multiprocessing` の API を利用してマルチスレッドを実現できる。\n",
        "\n",
        "実は、`multiprocessing.Pool` のサブクラスとして、スレッドプールを使用する `multiprocessing.pool.ThreadPool` クラスが定義されており、`multiprocessing.dummy.Pool()` は、この `ThreadPool` のインスタンスを返す。つまり、以下の 2 つのコードは等価である。\n",
        "\n",
        "``` python\n",
        "from multiprocessing.dummy import Pool\n",
        "pool = Pool(processes, initializer, initargs)\n",
        "```\n",
        "\n",
        "``` python\n",
        "from multiprocessing.pool import ThreadPool\n",
        "pool = ThreadPool(processes, initializer, initargs)\n",
        "```\n",
        "\n",
        "`queue.Queue` を利用して作成したスレッドプールと同じような動作を `Pool()` で実現できる。"
      ],
      "metadata": {
        "id": "bjVxTFf3YNUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing.dummy import Pool\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def worker(item):\n",
        "    print(f\"{threading.current_thread().name}: Working on {item}\")\n",
        "    time.sleep(item * 0.1)\n",
        "    print(f\"{threading.current_thread().name}: Finished {item}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # スレッドプールを設定（2 つのスレッドからなる）\n",
        "    with Pool(processes=2) as pool:\n",
        "        results = pool.map_async(func=worker, iterable=range(1, 6))\n",
        "        # スレッドの開始\n",
        "        results.get()\n",
        "    # 終了を待機\n",
        "    pool.join()\n",
        "    print(\"全てのタスクが完了した\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKCg4gTMddaf",
        "outputId": "3d619023-63a6-4488-9460-6a893f0de7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread-29 (worker): Working on 1\n",
            "Thread-30 (worker): Working on 2\n",
            "Thread-29 (worker): Finished 1\n",
            "Thread-29 (worker): Working on 3\n",
            "Thread-30 (worker): Finished 2\n",
            "Thread-30 (worker): Working on 4\n",
            "Thread-29 (worker): Finished 3\n",
            "Thread-29 (worker): Working on 5\n",
            "Thread-30 (worker): Finished 4\n",
            "Thread-29 (worker): Finished 5\n",
            "全てのタスクが完了した\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "フューチャーパターン\n",
        "--------------------"
      ],
      "metadata": {
        "id": "q5rVC8j9eRCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Pool` の `apply_async()` や `map_async()` で作成される結果オブジェクト（`ApplyResult` インスタンスや `MapResult` インスタンス）は、作成時にはタスクの結果を保持していなくても未来にはその結果を受け取ることができるという不思議なオブジェクトである。このようなオブジェクトは、しばしば future と呼ばれ、以下のようなデザインパターンの下でそのクラスが設計される。\n",
        "\n",
        "**フューチャーパターン**（future pattern）は、プロキシパターンの一種で、並列処理のためのデザインパターンである。値を取得できる既存クラスに対して、そのラッパーであるクラス（Future クラスと呼ぶ）を使って、次のような機能を追加する。\n",
        "\n",
        "  1. 既存クラスのインスタンスから値を取得できる場合は、その値を保持する。\n",
        "  2. 既存クラスのインスタンスから値を取得できない場合は、値を取得できる状態になるまで待つ。\n",
        "\n",
        "このように、Future クラスは待機状態を持つ。待機状態により値の取得を後回しにすることができ、これにより並列処理でのやり取りをスムーズに行うことができる。\n",
        "\n",
        "たとえば、ある計算を行うクラス X があって、その計算を要求する処理（receiver）と実際の計算を行う処理（sender）の間で以下のようなやり取りをする。\n",
        "\n",
        "  * （receiver） X クラスをラップする Future クラスをインスタンス化し、それを何らかの手段を用いて sender に渡す。\n",
        "  * （sender） X オブジェクトの計算を行い、Future オブジェクトの待機状態を解除する。\n",
        "  * （receiver） Future オブジェクトを確認し、待機状態が解除されていれば Future オブジェクトから計算結果を取得できるが、待機状態である間はブロックされる。\n",
        "\n",
        "X で行う計算が時間のかかるものである場合、Future オブジェクトを使うことで並列処理が効率的に行われる。\n",
        "\n",
        "Future の機能はよく引換券に例えられる（future は現物に対する先物という意味もある）。食券を発行する食堂で考えると、料理を要求する客と、料理を提供する食堂スタッフがいて、食堂ではすぐには料理が渡されないので、客は券売機で食券を購入して待つ。配膳口に食券の番号が表示されたら、客は配膳口で料理を受け取ることができる。食券システムによって客と食堂スタッフのやり取りがスムーズになり、客は料理ができるまでのスキマ時間を有効に活用することもできる。\n",
        "\n",
        "多くのプログラミング言語では、フューチャーパターンの実装が言語の機能あるいはライブラリとして取り込まれている。"
      ],
      "metadata": {
        "id": "NyUxJqtGeR8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "concurrent.futures\n",
        "------------------"
      ],
      "metadata": {
        "id": "elZCiIp-ySUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準ライブラリの `concurrent.futures` モジュールは、`multiprocessing.Pool` や `multiprocessing.dummy.Pool` の機能限定版となるインターフェースを提供する。スレッド間通信やプロセス間通信を使って細かい制御を行う必要がない、あるいは、そのような制御を使わないという制限を課す場合には、`concurrent.futures` モジュールが適している。"
      ],
      "metadata": {
        "id": "US0DmuvUZp1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Future ###"
      ],
      "metadata": {
        "id": "rbAA5FxgZqjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`concurrent.futures` モジュールが提供するインターフェースを使用すると、`concurrent.futures.Future` オブジェクトが作成される。これは、フューチャーパターンの Python 実装であり、タスクの未来の値を表す。`multiprocessing.pool.ApplyResult` より高機能である。モジュールの利用者がこのオブジェクトを直接作成する必要はなく、また操作するメソッドは次のメソッドに限られる。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `cancel()` | 呼び出しのキャンセルを試みる。呼び出しが現在実行中または実行が終了していてキャンセルできない場合、このメソッ<br />ドは `False` を返し、そうでない場合、呼び出しはキャンセルされ、このメソッドは `True` を返す | `bool` |\n",
        "| `cancelled()` | 呼び出しが正常にキャンセルされた場合 `True` を返す | `bool` |\n",
        "| `running()` | 現在呼び出しが実行中でキャンセルできない場合 `True` を返す | `bool` |\n",
        "| `done()` | 呼び出しが正常にキャンセルされたか終了した場合 `True` を返す | `bool` |\n",
        "| `result(timeout=None)` | 呼び出しによって返された値を返す。もし呼び出しがまだ完了していなければ、このメソッドは待機する。`timeout` に浮<br />動小数点数を指定した場合、タイムアウトすると `TimeoutError` が送出される。`Future` オブジェクトが完了する前にキャ<br />ンセルされた場合、`CancelledError` が送出される。呼び出しが例外を送出した場合、このメソッドは同じ例外を送出す<br />る | Unknown |\n",
        "| `exception(timeout=None)` | 呼び出しによって送出された例外を返す。もし呼び出しがまだ完了されていなければ、このメソッドは待機する。`timeout`<br /> に浮動小数点数を指定した場合および `Future` オブジェクトが完了する前にキャンセルされた場合は `result()` と同様。<br />呼び出しが例外を送出することなく完了した場合、`None` を返す | `Exception`<br /> &#124; `None` |\n",
        "| `add_done_callback(fn)` | 完了時コールバックとして呼び出し可能なオブジェクト `fn` を追加する。`Future` オブジェクトがキャンセルされたか、完了<br />した際に、`Future` オブジェクトをそのただ 1 つの引数として `fn` が呼び出される。追加された完了時コールバックは、追<br />加された順番で、追加を行ったプロセスに属するスレッド中で呼び出される。もし `Future` オブジェクトが既に完了してい<br />るか、キャンセル済みであれば、`fn` は即座に実行される | `None` |"
      ],
      "metadata": {
        "id": "Nl-7xp7PZsSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Executor ###"
      ],
      "metadata": {
        "id": "5eFs9zgN2gmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`concurrent.futures.Executor` は、スレッドまたはプロセスのプールを使用して非同期に呼び出しを行うインターフェースを提供するクラスである。以下のメソッドを持つ。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `submit(fn, /, *args, **kwargs)` | 呼び出し可能オブジェクト `fn` を `fn(*args, **kwargs)` として実行するようにスケジュールし、<br />`concurrent.futures.Future` オブジェクトを返す | `Future` |\n",
        "| `map(fn, *iterables, timeout=None,`<br />` chunksize=1)` | 組み込み関数 `map()` の非同期版。`fn` の実行結果（`Future` オブジェクトの `result()` メソッドの戻り値）を<br />返すジェネレーターを返す。返す順番は `iterables` で渡すタスクの順番となる（実行が完了した順番ではな<br />い）。`fn` 呼び出しで例外が発生した場合、その値がジェネレーターから取得される時にその例外が発生する。<br />`chunksize` はプロセスプールでのみ有効で `Pool.map()` と同じ | ｼﾞｪﾈﾚｰﾀｰ |\n",
        "| `shutdown(wait=True,`<br />` *, cancel_futures=False)` | シャットダウンする。以後 `submit()` と `map()` を呼び出すと `RuntimeError` が発生する。`cancel_futures`<br /> が `False`（デフォルト）の場合、実行を開始せず保留中の `Future` オブジェクトがキャンセルされず、それらの<br />全てが完了してリソースが解放される。`wait` が `True`（デフォルト）の場合、リソース解放までメソッドは返ら<br />ない | `None` |\n",
        "\n",
        "`Executor` は、コンテキストマネージャーとして使用できる。`shutdown()` は with ブロックを終了するときに呼び出される。\n",
        "\n",
        "`Executor` クラスを直接使ってはならず、サブクラスである `ThreadPoolExecutor`（マルチスレッド）か `ProcessPoolExecutor` （マルチプロセス）を介して使うこと。\n",
        "\n",
        "``` python\n",
        "concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `max_workers` | プールされるスレッドの数を指定する。`None` か指定を省略する場合のデフォルト値 `min(32, os.cpu_count() + 4)` |\n",
        "| `thread_name_prefix` | スレッド名の接頭辞を指定する |\n",
        "| `initializer` | スレッド開始時に実行する関数を指定する |\n",
        "| `initargs` | `initializer` の引数をタプルで指定する |\n",
        "\n",
        "``` python\n",
        "concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=(), max_tasks_per_child=None)\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `max_workers` | プールされるプロセスの数を指定する。`None` か指定を省略する場合のデフォルト値はマシン上の CPU コア数になる。Windows では 61 <br />以下に制約される |\n",
        "| `mp_context` | プロセス生成時の開始方式を指定する |\n",
        "| `initializer` | プロセス開始時に実行する関数を指定する |\n",
        "| `initargs` | `initializer` の引数をタプルで指定する |\n",
        "| `max_tasks_per_child` | Python 3.11 で追加。1 つのプロセスが実行できるタスクの最大数を指定する。この数を超えるとプロセスは終了する。`None`（デフォルト）<br />の場合、プロセスはプールと同じ期間存続する |\n",
        "\n",
        "`ProcessPoolExecutor` については、次の 3 点に注意する。\n",
        "\n",
        "  * `ProcessPoolExecutor` は、Python インタプリターの対話モードでは動作しない。\n",
        "  * `ProcessPoolExecutor` は、`multiprocessing.Queue` を利用しているため、pickle 化できるオブジェクトを利用する必要がある。pickle 化できないファイルオブジェクトやラムダ式などは、`ProcessPoolExecutor` で実行する呼び出し可能オブジェクト、その引数と戻り値として利用できない。\n",
        "  * `ProcessPoolExecutor` に渡された呼び出し可能オブジェクトから `Executor` や `Future` のメソッドを呼ぶとデッドロックに陥る。\n",
        "\n",
        "次のコードは、あえて効率の悪い素数判定アルゴリズムを用いた `is_prime()` 関数を、比較のため、シングルプロセスとマルチプロセスで動かす。マルチプロセスでは、さらに `submit()` メソッドと `map()` メソッドで動かしている。"
      ],
      "metadata": {
        "id": "Q3k8QCkT2hAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import time\n",
        "\n",
        "PRIMES = [\n",
        "    10897409,\n",
        "    20292113,\n",
        "    31518271,\n",
        "    40003027,\n",
        "]\n",
        "\n",
        "def is_prime(n: int) -> bool:\n",
        "    \"\"\"効率の悪い素数判定\"\"\"\n",
        "    if n < 2 or not isinstance(n, int):\n",
        "        raise ValueError(\"nは2以上の整数を指定してください\")\n",
        "    i = 2\n",
        "    while i < n:\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "        i += 1\n",
        "    return True\n",
        "\n",
        "def main():\n",
        "    # シングルプロセスで実行\n",
        "    print(f\"single process started at {time.strftime('%X')}\")\n",
        "    for n in PRIMES:\n",
        "        if is_prime(n):\n",
        "            print(f\"{n} is prime\")\n",
        "    print(f\"single process finished at {time.strftime('%X')}\")\n",
        "\n",
        "    # マルチプロセス（submit メソッド）で実行\n",
        "    print(f\"multi process (submit) started at {time.strftime('%X')}\")\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        n_futures = []\n",
        "        for n in PRIMES:\n",
        "            n_futures.append((n, executor.submit(is_prime, n)))\n",
        "        for n, future in n_futures:\n",
        "            if future.result():\n",
        "                print(f\"{n} is prime\")\n",
        "    print(f\"multi process (submit) finished at {time.strftime('%X')}\")\n",
        "\n",
        "    # マルチプロセス（map メソッド）で実行\n",
        "    print(f\"multi process (map) started at {time.strftime('%X')}\")\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for n, result in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
        "            if result:\n",
        "                print(f\"{n} is prime\")\n",
        "    print(f\"multi process (map) finished at {time.strftime('%X')}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7NINctuLFJQ",
        "outputId": "01868e2a-5d4a-4d3b-ef2c-ed86cea64efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "single process started at 02:40:22\n",
            "10897409 is prime\n",
            "20292113 is prime\n",
            "31518271 is prime\n",
            "40003027 is prime\n",
            "single process finished at 02:40:38\n",
            "multi process (submit) started at 02:40:38\n",
            "10897409 is prime\n",
            "20292113 is prime\n",
            "31518271 is prime\n",
            "40003027 is prime\n",
            "multi process (submit) finished at 02:40:51\n",
            "multi process (map) started at 02:40:51\n",
            "10897409 is prime\n",
            "20292113 is prime\n",
            "31518271 is prime\n",
            "40003027 is prime\n",
            "multi process (map) finished at 02:41:05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`submit()` メソッドは、1 個のタスクしか実行できないので、複数のタスクを同時に実行するには for 文を使うなどの工夫が必要である。\n",
        "\n",
        "`map()` メソッドは、イテラブルが返すタスクを実行できる。`multiprocessing.Pool` の `map_async()` に似ているが、複数の iterable 引数をサポートする（実行する `fn` 関数が複数の引数をとることができる）。`map()` メソッドはジェネレーターを返すが、そのジェネレーターは `Future` オブジェクトを返すのではなく、`Future` オブジェクトの `result()` メソッドの戻り値、つまり呼び出しの結果を返すことに注意する。上記のコードでは、結果表示のために、与えたタスクとその結果の組が欲しかったので、組み込み関数 `zip()` を使っている。`zip()` 関数が問題なく使えるのは、`map()` が返すジェネレーターでは完了した順番ではなく渡したタスクの順番で結果を受け取るからである。\n",
        "\n",
        "Colab の制約により、上の実行結果にはマルチプロセスの効果が表れなかった。手元のマシンでは、上記のコードを実行した結果にマルチプロセスの効果が表れたことを確認している。\n",
        "\n",
        "上記のコードは、`ProcessPoolExecutor` を `ThreadPoolExecutor` に単純に置換するだけで、マルチスレッドで動作する。ただし、`is_prime()` 関数は CPU バウンドな処理を行うので、GIL によってマルチスレッドの効果は表れない。\n",
        "\n",
        "さて、上記のコードの `is_prime()` 関数をタプル `tuple[int, bool]` を返すように変更する。この場合、`submit()` メソッドでは、完了時コールバックを追加し、完了時コールバックの中で結果を取得して上記コードと同様の結果表示を行える。また、`map()` メソッドでは、`zip()` を使う必要はない。"
      ],
      "metadata": {
        "id": "6evBpvVU4ukm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import Future, ProcessPoolExecutor\n",
        "import time\n",
        "\n",
        "PRIMES = [\n",
        "    10897409,\n",
        "    20292113,\n",
        "    31518271,\n",
        "    40003027,\n",
        "]\n",
        "\n",
        "def is_prime(n: int) -> tuple[int, bool]:\n",
        "    \"\"\"効率の悪い素数判定\"\"\"\n",
        "    if n < 2 or not isinstance(n, int):\n",
        "        raise ValueError(\"nは2以上の整数を指定してください\")\n",
        "    i = 2\n",
        "    while i < n:\n",
        "        if n % i == 0:\n",
        "            return n, False\n",
        "        i += 1\n",
        "    return n, True\n",
        "\n",
        "def my_callback_function(future: Future):\n",
        "    n, result = future.result()\n",
        "    if result:\n",
        "        print(f\"{n} is prime\")\n",
        "\n",
        "def main():\n",
        "    # マルチプロセス（submit メソッド）で実行\n",
        "    print(f\"multi process (submit) started at {time.strftime('%X')}\")\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for n in PRIMES:\n",
        "            future = executor.submit(is_prime, n)\n",
        "            future.add_done_callback(my_callback_function)\n",
        "    print(f\"multi process (submit) finished at {time.strftime('%X')}\")\n",
        "\n",
        "    # マルチプロセス（map メソッド）で実行\n",
        "    print(f\"multi process (map) started at {time.strftime('%X')}\")\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for n, result in executor.map(is_prime, PRIMES):\n",
        "            if result:\n",
        "                print(f\"{n} is prime\")\n",
        "    print(f\"multi process (map) finished at {time.strftime('%X')}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4oDiTpy6jin",
        "outputId": "85afaade-3429-4eb3-947b-8518a6b2aeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multi process (submit) started at 14:07:12\n",
            "10897409 is prime\n",
            "20292113 is prime\n",
            "31518271 is prime\n",
            "40003027 is prime\n",
            "multi process (submit) finished at 14:07:25\n",
            "multi process (map) started at 14:07:25\n",
            "10897409 is prime\n",
            "20292113 is prime\n",
            "31518271 is prime\n",
            "40003027 is prime\n",
            "multi process (map) finished at 14:07:38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### as_completed ###"
      ],
      "metadata": {
        "id": "kofZ_7MYwa34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "複数のタスクを同時に実行し、完了した `Future` オブジェクトから先に効率よく結果を受け取るということは、単純な `submit()` メソッドの繰り返しや `map()` メソッドを使う限りは実現できない。この場合、次のモジュール関数を使うとよい。\n",
        "\n",
        "``` python\n",
        "concurrent.futures.as_completed(fs, timeout=None)\n",
        "```\n",
        "\n",
        "この関数は、`Future` オブジェクトのイテレーター `fs` を受け取り、新たに完了順に `Future` オブジェクトを返すジェネレーターを返す。このジェネレーターから受け取る `Future` オブジェクトでは `result()` メソッドの呼び出しから直ちに結果を得る（または例外が発生する）。なお、`fs` は、異なる `Executor` インスタンスによって作成された `Future` オブジェクトを返すものであってもよい。\n",
        "\n",
        "`timeout` 引数を指定した場合、`timeout` 秒経過してもジェネレーターが `Future` オブジェクトを返さないとき、`concurrent.futures.TimeoutError` 例外を発生させる。\n",
        "\n",
        "以下は、HTTP リクエストを伴う大量のタスクのバッチ処理を想定したコード例である。処理が I/O バウンドなので、`ThreadPoolExecutor` で並列処理を行っている。例外処理も行うようにしている。ここでは、 [httpstat.us](https://httpstat.us/) にアクセスし HTTP Status Code のレスポンスを得ているだけである。 httpstat.us は、URL に欲しいステータスコードの番号を付けてアクセスするだけで、そのステータスコードのレスポンスを返してくれるサービスを提供している。`https://httpstat.us/200` なら `200 OK` のステータスコードである。`sleep=<millisecond>` の形でクエリ文字列を追加すると、`<millisecond>` ミリ秒経過までレスポンスを遅らせることができる。"
      ],
      "metadata": {
        "id": "DDofQWIKwbgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import Future, ThreadPoolExecutor, TimeoutError, as_completed\n",
        "import urllib.request\n",
        "\n",
        "def my_task(millisecond: int) -> tuple[str, int]:\n",
        "    if millisecond < 0:\n",
        "        raise ValueError(f\"millisecond is {millisecond}, must be greater than or equal to 0\")\n",
        "    with urllib.request.urlopen(f\"https://httpstat.us/200?sleep={millisecond}\") as response:\n",
        "        body = response.read().decode(\"utf-8\")\n",
        "        return body, millisecond\n",
        "\n",
        "def my_add_done_callback(future: Future):\n",
        "    try:\n",
        "        result = future.result()\n",
        "    except ValueError as err:\n",
        "        print(f\"{type(err).__name__}: {err}\")\n",
        "    else:\n",
        "        print(f\"Task completed: {result}\")\n",
        "\n",
        "def main():\n",
        "    # タスクのリスト（遅延する時間（ミリ秒）を指定する）\n",
        "    tasks = [3000, 1000, 2000, 4000, 6000, -1000]\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = [executor.submit(my_task, millisecond=task) for task in tasks]\n",
        "        try:\n",
        "            # タイムアウトを 6 秒に設定するので、おそらく 6000 のタスクはタイムアウトする\n",
        "            for future in as_completed(futures, timeout=6.0):\n",
        "                future.add_done_callback(my_add_done_callback)\n",
        "        except TimeoutError as err:\n",
        "            print(f\"{type(err).__name__}: {err}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy-xK51kbIJq",
        "outputId": "388be1b1-6acf-445e-a32f-46a2500d46be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: millisecond is -1000, must be greater than or equal to 0\n",
            "Task completed: ('200 OK', 1000)\n",
            "Task completed: ('200 OK', 2000)\n",
            "Task completed: ('200 OK', 3000)\n",
            "Task completed: ('200 OK', 4000)\n",
            "TimeoutError: 1 (of 6) futures unfinished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "呼び出しで発生した例外は、`Future` オブジェクトの `result()` メソッドで結果を取得する際に処理する。`as_completed()` 関数で発生した `concurrent.futures.TimeoutError` 例外は、関数の呼び出しを try-except 文で書いて処理する。"
      ],
      "metadata": {
        "id": "Sb1EQLxroXkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 排他制御 ###"
      ],
      "metadata": {
        "id": "2JXN5VpZoYdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチスレッドでは、競合状態が発生する場合、ロックを使用する必要がある。"
      ],
      "metadata": {
        "id": "2Rs1cqONp-m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from threading import Lock, current_thread\n",
        "import time\n",
        "\n",
        "def counter(data: dict, lock: Lock):\n",
        "    with lock:  # ロックの獲得と解放\n",
        "        n = data['n']\n",
        "        time.sleep(0.2)\n",
        "        data['n'] = n + 1\n",
        "        print(f\"{current_thread().name}: {data['n']=}\")\n",
        "\n",
        "def main():\n",
        "    data = {\"n\": 0}\n",
        "    lock = Lock()  # ロックを作成\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for _ in range(3):\n",
        "            executor.submit(counter, data, lock)\n",
        "    print(f\"{current_thread().name}: {data['n']=}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4VFcWwZuDwG",
        "outputId": "bb04f831-eeea-4e3e-fb58-4e407387a827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ThreadPoolExecutor-1_0: data['n']=1\n",
            "ThreadPoolExecutor-1_1: data['n']=2\n",
            "ThreadPoolExecutor-1_2: data['n']=3\n",
            "MainThread: data['n']=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "subprocess\n",
        "----------"
      ],
      "metadata": {
        "id": "6lkjTSW3NMEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準ライブラリの `subprocess` モジュールは、新しいプロセスの開始、入力・出力・エラーパイプの接続、リターンコードの取得を可能とする。"
      ],
      "metadata": {
        "id": "a4_Zd9KyNMnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run ###"
      ],
      "metadata": {
        "id": "S-MARoXHNOaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` python\n",
        "subprocess.run(args, *, **kwargs)\n",
        "```\n",
        "\n",
        "このモジュール関数は、`args`（文字列のリストまたは単一の文字列）で指定されたコマンドを実行する。コマンドの完了を待って、`subprocess.CompletedProcess` インスタンスを返す。\n",
        "\n",
        "`args` 以外の引数は、すべてキーワード専用引数となっており、主なものは次のとおり（全てのキーワード専用引数は[公式ドキュメント](https://docs.python.org/ja/3/library/subprocess.html#using-the-subprocess-module)を参照）。\n",
        "\n",
        "| kwargs | 意味 | default |\n",
        "|:---|:---|:--:|\n",
        "| `stdin` | 標準入力を指定する。以下から選ぶ<br /><br />・`None`: リダイレクトは発生しない<br /><br />・`subprocess.PIPE`: 子プロセスへの新しいパイプを作成する<br /><br />・`subprocess.DEVNULL`: `os.devnull` を使用する<br /><br />・ファイル記述子（正の整数）<br /><br />・有効なファイル記述子を持つファイルオブジェクト | `None` |\n",
        "| `stdout` | 標準出力を指定する。`stdin` と同じ項目を選べる | `None` |\n",
        "| `stderr` | 標準エラー出力を指定する。`stdout` で選べる項目に加え、`subprocess.STDOUT` も選べる。これは子プロセスからの `stderr` の<br />内容が `stdout` と同じファイルハンドルにキャプチャされる必要があることを示す | `None` |\n",
        "| `capture_output` | `True` の場合、標準出力と標準エラー出力の内容がそれぞれ `CompletedProcess` インスタンスの `stdout` 属性と `stderr` 属性で<br />参照できる | `False` |\n",
        "| `shell` | `args` が単一の文字列で `shell` が `True` の場合、その文字列がシェルによって実行される。`args` が単一の文字列で `shell` が<br /> `False`（デフォルト）の場合、その文字列は引数を指定せずに実行される単なるプログラムの名前でなければならない | `False` |\n",
        "| `cwd` | 作業ディレクトリのパスを表す path-like オブジェクトを指定する | `None` |\n",
        "| `timeout` | `timeout` 秒経過後に処理が完了しなかった場合に `subprocess.TimeoutExpired` 例外を送出する。`timeout` が `None`（デフォル<br />ト）の場合、タイムアウトしない | `None` |\n",
        "| `check` | `True` の場合、子プロセスが非ゼロの終了コードで終了したなら、`subprocess.CalledProcessError` 例外を送出する | `False` |\n",
        "\n",
        "`subprocess.CompletedProcess` の属性:\n",
        "\n",
        "| 属性 | 意味 |\n",
        "|:---|:---|\n",
        "| `args` | プロセスを起動するときに使用された引数。1 個のリストか 1 個の文字列になる |\n",
        "| `returncode` | 子プロセスの終了コード。正常終了の場合 `0` を返す |\n",
        "| `stdout` | 子プロセスから補足された標準出力の内容（バイト列） |\n",
        "| `stderr` | 子プロセスから補足された標準エラー出力の内容（バイト列） |\n",
        "\n",
        "`subprocess.CompletedProcess` のメソッド:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `check_returncode()` | 終了コードが非ゼロの場合、`subprocess.CalledProcessError` が送出される | `None` |\n",
        "\n",
        "次は、`capture_output` 引数を設定して、標準出力と標準エラー出力を捕捉するコード例である。"
      ],
      "metadata": {
        "id": "5r3h3X9KNQn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "obj = subprocess.run([\"ls\", \"-l\"], capture_output=True)\n",
        "print(\"stdout:\\n{}\".format(obj.stdout.decode(\"utf-8\")))\n",
        "print(\"stdout:\\n{}\".format(obj.stderr.decode(\"utf-8\")))  # 捕捉した内容がない場合は None を返す"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYkv-_pBZ9uN",
        "outputId": "f48a5a80-4227-412b-9fda-9cdbb6df45ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stdout:\n",
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jul  1 13:21 sample_data\n",
            "\n",
            "stdout:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これは、 `stdout` 引数と `stderr` 引数に `subprocess.PIPE` を設定する次のコードと同じである。"
      ],
      "metadata": {
        "id": "gXAeKZdQaeuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "obj = subprocess.run([\"ls\", \"-l\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "print(\"stdout:\\n{}\".format(obj.stdout.decode(\"utf-8\")))\n",
        "print(\"stdout:\\n{}\".format(obj.stderr.decode(\"utf-8\")))  # 捕捉した内容がない場合は None を返す"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDE-yj8RYR1X",
        "outputId": "5f7c7307-7edd-4e7a-d410-96827c7a996f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stdout:\n",
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jul  1 13:21 sample_data\n",
            "\n",
            "stdout:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は、`check` 引数を設定して、子プロセスが正常終了しなかった場合に `subprocess.CalledProcessError` 例外を送出するコード例である。"
      ],
      "metadata": {
        "id": "j703_PDAkJF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "try:\n",
        "    # シェルでコマンド \"exit 1\" を実行する\n",
        "    obj = subprocess.run(\"exit 1\", shell=True, check=True)\n",
        "except subprocess.CalledProcessError as err:\n",
        "    print(f\"{type(err).__name__}: {err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9619D3SkKEd",
        "outputId": "eaf4406e-4be9-4d03-edd1-ee690289d248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CalledProcessError: Command 'exit 1' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これは、戻り値オブジェクトの `check_returncode()`メソッド を呼び出す次のコードと同じである。"
      ],
      "metadata": {
        "id": "ViQBVuolmGJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# シェルでコマンド \"exit 1\" を実行する\n",
        "obj = subprocess.run(\"exit 1\", shell=True)\n",
        "try:\n",
        "    obj.check_returncode()\n",
        "except subprocess.CalledProcessError as err:\n",
        "    print(f\"{type(err).__name__}: {err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OPjkWeNmG6Y",
        "outputId": "272e61c9-ab92-42ab-f7ea-e84469c96a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CalledProcessError: Command 'exit 1' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は、`timeout` 引数を設定して、タイムアウトするコード例である。"
      ],
      "metadata": {
        "id": "owCiY8gpoOjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "try:\n",
        "    subprocess.run([\"sleep\", \"10\"], timeout=1.0)\n",
        "except subprocess.TimeoutExpired as err:\n",
        "    print(f\"{type(err).__name__}: {err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip4ncLAkoO_g",
        "outputId": "4b527a4a-cc45-496f-9ece-0648b230a201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeoutExpired: Command '['sleep', '10']' timed out after 0.9999655629999893 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Popen ###"
      ],
      "metadata": {
        "id": "6CCLcFtIs7mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実のところ、`subprocess.run()` 関数は、内部的にそのキーワード引数を伴い `subprocess.Popen` インスタンス化を呼び出している。`subprocess.run()` 関数よりも高度な処理を行いたい場合は、`subprocess.Popen` クラスを直接利用する。\n",
        "\n",
        "`subprocess.Popen` は、`subprocess.CompletedProcess` と同様の属性を持ち、さらに `pid` 属性で子プロセスのプロセス ID を参照できる。\n",
        "\n",
        "`subprocess.Popen` のメソッド:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `poll()` | 子プロセスの実行が終了したら終了コードを返す。終了してないなら `None` を返す | `int` &#124; `None` |\n",
        "| `wait(timeout=None)` | 子プロセスが終了するまで待機し、終了したら終了コードを返す。`timeout` を設定した場合、<br />プロセスが `timeout` 秒経過後に終了してない場合、`TimeoutExpired` 例外を送出する | `int` &#124; `None` |\n",
        "| `communicate(input=None, timeout=None)` | 子プロセスが終了するまで待機し、標準出力と標準エラー出力を読み込む | 標準出力と標準エラー<br />出力の組となるタプル |\n",
        "| `send_signal(signal)` | `signal` を子プロセスに送る | `None` |\n",
        "| `terminate()` | 子プロセスを停止する | `None` |\n",
        "| `kill()` | 子プロセスを強制終了する | `None` |\n",
        "\n",
        "シェル上で `|` を使ったパイプライン処理は、2 つの子プロセスの標準出力と標準入力をパイプでつなぐことで記述することができる。"
      ],
      "metadata": {
        "id": "7IUD5MTps8PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# 2つの子プロセスをパイプで繋ぐ\n",
        "p1 = subprocess.Popen([\"ls\", \"-l\", \"sample_data\"], stdout=subprocess.PIPE)\n",
        "p2 = subprocess.Popen([\"grep\", \"json\"], stdin=p1.stdout, stdout=subprocess.PIPE)\n",
        "out, err = p2.communicate()  # ls -l sample_data | grep json\n",
        "print(out.decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVRSMOIHuREH",
        "outputId": "9e6cfa36-adb4-48f0-ad79-b7e959c03b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ファイルロック\n",
        "--------------"
      ],
      "metadata": {
        "id": "Az0NE4K5wucz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "複数のプロセスが同時に同じファイルにアクセスすると、意図しない上書きや部分的なデータ損失が発生し、アプリケーションの誤動作を引き起こす。\n",
        "\n",
        "例えば、現金の出納を記録する CSV 形式が次のようなものであったとする。\n",
        "\n",
        "``` text\n",
        "日付,摘要,入金額,出金額,残高\n",
        "2025-04-01,前月繰越,150_000,,150_000\n",
        "```\n",
        "\n",
        "プロセス A およびプロセス B が同時に CSV 形式をファイルから読み込み、まずプロセス A が 50000 円の入金を計算してファイルにそのレコード全体を書き戻すと CSV 形式は次のようになる。\n",
        "\n",
        "``` text\n",
        "日付,摘要,入金額,出金額,残高\n",
        "2025-04-01,前月繰越,150_000,,150_000\n",
        "2025-04-07,預金より現金補充,50_000,,200_000\n",
        "```\n",
        "\n",
        "その後、プロセス B が 100000 円の出金を記録してファイルにそのレコード全体を書き戻すと、ファイルがプロセス B によって上書きされ、プロセス A が加えた変更が失われてしまう。\n",
        "\n",
        "``` text\n",
        "日付,摘要,入金額,出金額,残高\n",
        "2025-04-01,前月繰越,150_000,,150_000\n",
        "2025-04-07,事務所備品（PC）購入,,100_000,50_000\n",
        "```\n",
        "\n",
        "プロセス A とプロセス B が共に `multiprocessing` によって生成された子プロセスであれば、`multiprocessing.Lock` を使ってファイルの更新をシリアライズ（逐次化）することでこの問題を防ぐことができる。しかし、この解決法はプロセス A とプロセス B が互いに外部プロセスである場合には使えない。\n",
        "\n",
        "そこで、ファイル自体についてプロセスによる更新をシリアライズする方法が必要となる。この方法が**ファイルロック**（file lock）である。"
      ],
      "metadata": {
        "id": "NvoZvaNRwwPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ファイルロックの種類 ###"
      ],
      "metadata": {
        "id": "S6rTSljJOk1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ファイルロックには、ファイルにアクセスする権利の種類により排他ロックと共有ロックという違いがあり、また、他のプロセスがすでにロックしている場合に待つかどうかでブロッキングとノンブロッキングという違いがある。\n",
        "\n",
        "  * **排他ロック**： 他のプロセスがそのファイルを一切読み書きできなくなる。\n",
        "  * **共有ロック**： 他のプロセスは読み取りはできるが、書き込みはできない。\n",
        "  * **ブロッキング**： 他のプロセスがすでにロックしている場合、解除されるまで待つ（タイムアウトするまでロックをリトライする）。\n",
        "  * **ノンブロッキング**： 他のプロセスがすでにロックしている場合、直ちにエラーが発生する。"
      ],
      "metadata": {
        "id": "-LQbZmonOljR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 強制ロック ###"
      ],
      "metadata": {
        "id": "mEwH1e5NwygR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Windows は、強制的にファイルのアクセスを制御することが可能である。これを**強制ロック**（mandatory lock）という。\n",
        "\n",
        "Windows API の関数 `CreateFile()` でファイルを開く際に引数 `dwShareMode` で共有モード（読み取り、書き込み、削除）を指定し、それ以外のアクセスを拒否できる。ファイルを閉じると、設定した共有モードによるアクセス制限が解除される。\n",
        "\n",
        "また、ロック単位はファイル全体または部分（バイト単位）で指定することも可能である。\n",
        "\n",
        "Python からファイルロックに関する Windows API を呼び出すには、標準ライブラリの `msvcrt` モジュールが提供する次の関数を使用する。\n",
        "\n",
        "``` python\n",
        "msvcrt.locking(fd, mode, nbytes)\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `fd` | ファイルディスクリプタ |\n",
        "| `mode` | ロックの種類 |\n",
        "| `nbytes` | ロックのバイト数。現在のファイル位置からのバイト数までとして指定する |\n",
        "\n",
        "`mode` 引数には以下のモジュール定数を指定することができる。\n",
        "\n",
        "| モジュール定数 | ロックの種類 | ブロッキング |\n",
        "|:---|:---|:---|\n",
        "| `msvcrt.LK_LOCK` | 排他ロック | ブロッキング |\n",
        "| `msvcrt.LK_RLCK` | 共有ロック | ブロッキング |\n",
        "| `msvcrt.LK_NBLCK` | 排他ロック | ノンブロッキング |\n",
        "| `msvcrt.LK_NBRLCK` | 共有ロック | ノンブロッキング |\n",
        "| `msvcrt.LK_UNLCK` | ロック解除 | |\n",
        "\n",
        "ブロッキングの場合、Windows API では 1 秒ごとに 10 回までロックを試みる。ロックできなければ `OSError` が発生する。ノンブロッキングの場合、直ちに `OSError` が発生する。\n",
        "\n",
        "ファイル全体にロックをかけたい場合は、先頭にシークしてサイズ分を指定する。\n",
        "\n",
        "``` python\n",
        "import msvcrt\n",
        "\n",
        "with open(\"data.txt\", \"r+\") as f:\n",
        "    f.seek(0, 2)  # ファイル末尾へ（サイズ取得用）\n",
        "    size = f.tell()\n",
        "    f.seek(0)  # 先頭に戻す\n",
        "\n",
        "    try:\n",
        "        msvcrt.locking(f.fileno(), msvcrt.LK_LOCK, size)  # 全体ロック\n",
        "        # 安全に読み書き\n",
        "    finally:\n",
        "        msvcrt.locking(f.fileno(), msvcrt.LK_UNLCK, size)  # ロック解除\n",
        "```\n",
        "\n",
        "強制ロックの場合、ロック中に他プロセスが読み書きしようとすると失敗するので、安全性が高い。その反面、OS が毎回ロック状態をチェックするため、オーバーヘッドがある。また、プロセスがロックを解除しないために起こる「ファイルの使用中」エラーに遭遇しやすい。"
      ],
      "metadata": {
        "id": "74YziizQw09X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### アドバイザリーロック ###"
      ],
      "metadata": {
        "id": "CeTKjjoryjYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linux や macOS は、ファイルについてロック/アンロックという状態（ビットフラグ）を変更することができるが、プロセスに強制しない。これを**アドバイザリーロック**（advisory lock）という。ロックに従うかどうかはアプリケーションの設計次第であり、ロックを無視して読み書きすることも技術的には可能である。\n",
        "\n",
        "Linux や macOS が強制ロックを採用しない理由は、POSIX 準拠のファイルパーミッションと強制ロックを両立させる実装が難しいからであると言われている。\n",
        "\n",
        "ファイルの状態（ビットフラグ）の変更や確認は `fcntl()` システムコールを使う。\n",
        "\n",
        "Python からファイルロックに関して C の `fcntl()` システムコールを行うには、標準ライブラリの `fcntl` モジュールが提供する次の関数を使用する。\n",
        "\n",
        "``` python\n",
        "fcntl.lockf(fd, cmd, len=0, start=0, whence=0)\n",
        "```\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `fd` | ファイルディスクリプタ（または `fileno()` メソッドを提供しているファイルオブジェクト） |\n",
        "| `cmd` | 操作の種類 |\n",
        "| `len` | ロックのバイト数。`0`（デフォルト）の場合、ファイルの終了までロックすることを表す |\n",
        "| `start` | ロック領域先頭の `whence` からの相対的なバイトオフセット。デフォルトは `0` |\n",
        "| `whence` | `io.FileIO.seek()` の同名引数と同じ。デフォルトは `0`（ファイルの先頭位置） |\n",
        "\n",
        "`cmd` 引数には以下のモジュール定数を指定することができる。\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `fcntl.LOCK_EX` | 排他ロック |\n",
        "| `fcntl.LOCK_SH` | 共有ロック |\n",
        "| `fcntl.LOCK_NB` | ノンブロッキング。`fcntl.LOCK_EX` か `fcntl.LOCK_SH` とビット演算子 `|` による論理和で指定 |\n",
        "| `fcntl.LOCK_UN` | ロック解除 |\n",
        "\n",
        "この関数は、ロックの取得に失敗すると `BlockingIOError` 例外を送出する。"
      ],
      "metadata": {
        "id": "d-QAyq6WykJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 適当にファイルを作成しておく\n",
        "!touch data.txt\n",
        "\n",
        "import fcntl\n",
        "\n",
        "with open(\"data.txt\", \"r+\") as f:\n",
        "    fcntl.lockf(f, fcntl.LOCK_EX)  # 排他ロック（ブロッキング）\n",
        "    # 安全に読み書き\n",
        "    fcntl.lockf(f, fcntl.LOCK_UN)  # ロック解除"
      ],
      "metadata": {
        "id": "n6xkq5zEejsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ロックファイル ###"
      ],
      "metadata": {
        "id": "QFrR1cO1jMZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OS によってファイルロックの実装、挙動が異なるため、クロスプラットフォーム対応なアプリケーションでは問題となる。\n",
        "\n",
        "そこで、強制ロックにもアドバイザリーロックにも依存しないで独自にファイルロック機能を実装することがある。具体的には、「一時的なファイルを新規作成できたらロックの取得とみなす」という方法で実装する。この一時的なファイルを**ロックファイル**（lock file）と呼ぶ。\n",
        "\n",
        "次のコードは、シンプルなロックファイル方式の実装例である。"
      ],
      "metadata": {
        "id": "n3eTQeBnjM4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 適当にファイルを作成しておく\n",
        "!touch data.txt\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class FileLock:\n",
        "    def __init__(self, lock_file_path):\n",
        "        self.lock_file = Path(lock_file_path)\n",
        "\n",
        "    def acquire(self):\n",
        "        \"\"\"ロックを取得する\"\"\"\n",
        "        try:\n",
        "            # 'x' モードを指定してロックファイルを排他的に作成（既に存在する場合は失敗）\n",
        "            with open(self.lock_file, 'x') as f:\n",
        "                # プロセスIDを書き込んでおく（デバッグ用）\n",
        "                f.write(str(os.getpid()))\n",
        "            return True\n",
        "        except FileExistsError:\n",
        "            # 既にロックが存在する場合\n",
        "            return False\n",
        "\n",
        "    def release(self):\n",
        "        \"\"\"ロックを解放する\"\"\"\n",
        "        try:\n",
        "            self.lock_file.unlink()\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            # ロックファイルが存在しない場合\n",
        "            return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 基本的な使用方法\n",
        "    file = \"data.txt\"\n",
        "    lockfile = \"data.txt.lock\"\n",
        "\n",
        "    lock = FileLock(lockfile)\n",
        "\n",
        "    if lock.acquire():\n",
        "        try:\n",
        "            with open(\"data.txt\", \"r+\") as f:\n",
        "                ... # 安全に読み書き\n",
        "        finally:\n",
        "            lock.release()"
      ],
      "metadata": {
        "id": "lKLlOvR2z47X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`FileLock` の `acquire()` メソッドでロックを取得する（成功時に `True`、失敗時に `False` を返す）。ロックファイルが既に存在する場合は `FileExistsError` が発生するため、これでロック状態を判定している。タイムアウト付きリトライ機能は含んでいない。\n",
        "\n",
        "`FileLock` の `release()` メソッドでロックを解放する。\n",
        "\n",
        "ロックファイル方式の使用方法において、ファイルの読み書きの部分を全く別のタスクに置き換えても問題がない。こうして、ロックファイル方式はファイルロック以外にも応用できる。例えば、プロセスの多重起動防止、リソースの排他利用、複数ジョブ間の依存関係制御（ジョブ A が完了したらロックファイルを削除、ジョブ B はその削除を待つ）など。\n",
        "\n",
        "ロックファイル方式はプラットフォームに依存しない反面、プロセスの強制終了などでロックファイルが残るとデッドロックの原因になるため、注意が必要。"
      ],
      "metadata": {
        "id": "xUFIps0oToit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filelock ###"
      ],
      "metadata": {
        "id": "m0e-Nk79aN5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "サードパーティ製 [filelock](https://py-filelock.readthedocs.io/en/latest/) パッケージは、高機能で安全なロックファイル方式の実装を提供している。ライセンスは Unlicense。インストール方法は次のとおり。\n",
        "\n",
        "``` python\n",
        "pip install filelock\n",
        "```\n",
        "\n",
        "「ロックファイルの存在」だけでロック状態とみなす方式では、プロセスが強制終了したときにデッドロックが発生する可能性が高くなる。そこで、`filelock` は「ロックファイルの存在」ではなく「ロックファイルの排他アクセス」をロック状態とみなす。この方式ではロックを解除するときにロックファイルを削除する必要がない。\n",
        "\n",
        "`filelock.FileLock` クラスは、クロスプラットフォーム対応のロックファイル方式を実装するもので、Windows 環境では `msvcrt` を使用する `filelock.WindowsFileLock` クラスの別名であり、それ以外の環境では `fcntl` を使用する `filelock.UnixFileLock` クラスの別名である。コンストラクタは次のとおり。\n",
        "\n",
        "``` python\n",
        "filelock.FileLock(lock_file, timeout=-1, mode=420, thread_local=True, *, blocking=True, is_singleton=False)\n",
        "```\n",
        "\n",
        "主な引数は次のとおり。\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `lock_file` | ロックファイルのパス（文字列またはファイルオブジェクト）。このファイルが存在しない場合は作成され、ロックに使用される |\n",
        "| `timeout` | ロック獲得のために待機する最大秒数（`float`）。その間にロックを取得できなければ `filelock.Timeout` 例外を送出する。`0` の場合、ロックを取得<br />できなければ待機せずに直ちに `filelock.Timeout` 例外を送出する。`-1`（デフォルト）の場合、無限に待つ |\n",
        "\n",
        "主なメソッドは次のとおり。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `acquire(timeout=None, poll_interval=0.05,`<br />` *, poll_intervall=None, blocking=None)` | ロックを取得する | `AcquireReturnProxy` |\n",
        "| `release()` | ロックを解放する。ロックファイルは自動的には削除されない | `None` |\n",
        "\n",
        "`filelock.FileLock` オブジェクトはコンテキストマネージャーであるため with 構文をサポートする。`__enter__()` メソッドはオブジェクトの `acquire()` メソッドを呼び出した後にオブジェクト自身を返す。`__exit__()` メソッドはオブジェクトの `release()` メソッドを実行する。\n",
        "\n",
        "次のコードは `filelock.FileLock` の使用例:"
      ],
      "metadata": {
        "id": "8SSb0oulaOqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 適当にファイルを作成しておく\n",
        "!touch data.txt\n",
        "\n",
        "from filelock import FileLock\n",
        "\n",
        "lock = FileLock(\"data.txt.lock\", timeout=10)\n",
        "with lock:\n",
        "    with open(\"data.txt\", \"r+\") as f:\n",
        "        ... # 安全に読み書き"
      ],
      "metadata": {
        "id": "mucigohJaQ6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}