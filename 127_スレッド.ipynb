{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPhvf/yyhfUUdJjjDXSPNRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suwatoh/Python-learning/blob/main/127_%E3%82%B9%E3%83%AC%E3%83%83%E3%83%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "スレッド\n",
        "========"
      ],
      "metadata": {
        "id": "enRm31HrFafz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチコアとマルチスレッド\n",
        "--------------------------"
      ],
      "metadata": {
        "id": "yYU0pc-Yonj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 並行処理と並列処理 ###"
      ],
      "metadata": {
        "id": "AX1zuRGc2t9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "現代の CPU の内部には、独立して処理作業を行う回路のブロックが複数組み込まれており、それぞれが単体の処理装置のように振る舞う。これらを **CPU コア**と呼ぶ。CPU が複数の CPU コアを持つことを**マルチコア**（multi-core）と表現する。\n",
        "\n",
        "CPU コアに処理させる対象が複数あって、処理を「同時に」行わせたい場合、CPU コアの処理形態には次の 2 種類がある。\n",
        "\n",
        "  * **並行処理**（concurrent processing）:  \n",
        "*1 個の CPU コア* が複数の処理を切り替えながら進めること。「複数の処理を切り替え」るとは、開始した処理を中断し、別の処理を再開することをいう。\n",
        "  * **並列処理**（parallel processing）:  \n",
        "*複数の CPU コア* が割り振られた処理を同時に進めること。\n",
        "\n",
        "並行処理では、どの時間でも 1 個の CPU コアが 1 つの処理作業を行っているにすぎないが、処理の切り替えを素早く行うことによって「同時に」行っているように見せかける。これは、ワンオペレーションの飲食店で全ての作業が切り盛りされる様子に似ている（画像は[いらすとや](https://www.irasutoya.com/2018/06/blog-post_850.html)より）。\n",
        "\n",
        "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5Dn4bGYN7AWxje4ecO8Ezh6Qqdn82HjlXE2iJtVj8Sl51a6DKoUTr5YrLloo8wRlf13YuzBPRAJ_mKW2TtYhOSIrAOiNg1WTBEpbMdf5enBQuuWnu6zeoxd2qhptHd-YYtUPwB01dKIA0/s800/job_one_operation_man.png\" width=\"400\">\n",
        "\n",
        "並列処理では、複数の CPU コアを使って真の意味で「同時に」処理が進められるので、並行処理より確実に処理時間が短くなる。しかしながら、並列処理を行うには同時に行う処理の数に対して CPU コアの数が足りていることが必要であり、この条件がいつも満たされるとは限らない。"
      ],
      "metadata": {
        "id": "gw8zmv9y2uwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロセス ###"
      ],
      "metadata": {
        "id": "_KEypNPJVt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**プロセス**（process）は、プログラムを実行する実体（インスタンス）である。ハードディスク上に存在するプログラムがメモリ上に展開され、CPU で実行されている状態を指す。OS は、各プロセスを識別するために**プロセス ID**（process ID; PID）と呼ばれる一意な識別子を割り当てる。Linux では `ps` コマンド、Windows では `tasklist` コマンドで現在実行中のプロセスが一覧表示される。プロセスが終了すると、OS は割り当てたメモリを解放する。"
      ],
      "metadata": {
        "id": "6lYfa1goC5hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvOdkw1oC6rD",
        "outputId": "2ace11ac-3afb-42e3-92f3-f557510b4619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 docker-init\n",
            "      7 ?        00:00:00 node\n",
            "     11 ?        00:00:00 oom_monitor.sh\n",
            "     13 ?        00:00:00 run.sh\n",
            "     14 ?        00:00:00 kernel_manager_\n",
            "     37 ?        00:00:00 tail\n",
            "     63 ?        00:00:06 python3 <defunct>\n",
            "     64 ?        00:00:00 colab-fileshim.\n",
            "     82 ?        00:00:03 jupyter-noteboo\n",
            "     83 ?        00:00:00 dap_multiplexer\n",
            "    599 ?        00:00:03 python3\n",
            "    626 ?        00:00:00 python3\n",
            "    654 ?        00:00:00 language_servic\n",
            "    662 ?        00:00:18 node\n",
            "    794 ?        00:00:00 sleep\n",
            "    795 ?        00:00:00 ps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "実行中のプロセスに関して、以下の Python 関数が利用できる。\n",
        "\n",
        "| 関数 | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `os.getpid()` | 実行中のプロセス ID を返す | `int` |\n",
        "| `os.getppid()` | 親プロセス（実行中のプロセスを生成したプロセス）のプロセス ID を返す | `int` |"
      ],
      "metadata": {
        "id": "TrXG2ByLQfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getpid(), os.getppid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRLbaT9vQhAF",
        "outputId": "a638f280-6e20-4d9a-f153-acc341e9f605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(599, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unix 系 OS では、実行中のプロセスに関する情報を取得・設定する以下の Python 関数が利用できる。\n",
        "\n",
        "| 関数 | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `os.getuid()` | 実行中のプロセスの実ユーザー ID を返す | `int` |\n",
        "| `os.geteuid()` | 実行中のプロセスの実効ユーザー ID を返す | `int` |\n",
        "| `os.getgid()` | 実行中のプロセスの実グループ ID を返す | `int` |\n",
        "| `os.getegid()` | 実行中のプロセスの実効グループ ID を返す | `int` |\n",
        "| `os.getgroups()` | 実行中のプロセスに関連付けられた従属グループ ID のリストを返す | `list` |\n",
        "| `os.getpriority(which, who)` | プログラムのスケジューリング優先度を取得する。`which` は `PRIO_PROCESS`、`PRIO_PGRP`、または `PRIO_USER`<br /> のいずれかとする。`who` は `which` に応じて解釈される（`PRIO_PROCESS` であればプロセス ID、`PRIO_PGRP` で<br />あればプロセスグループ ID、そして `PRIO_USER` であればユーザー ID)。`who` が `0` の場合、実行中のプロセス、<br />そのグループと実ユーザー ID を意味する | `list` |\n",
        "| `os.setuid(uid, /)` | 実行中のプロセスのユーザー id を設定する | `int` |\n",
        "| `os.seteuid(euid, /)` | 実行中のプロセスに実効ユーザー ID をセットする | `None` |\n",
        "| `os.setgid(gid, /)` | 実行中のプロセスにグループ ID をセットする | `None` |\n",
        "| `os.setegid(egid, /)` | 実行中のプロセスに実効グループ ID をセットする | `None` |\n",
        "| `os.setgroups(groups, /)` | 実行中のグループに関連付けられた従属グループ ID のリストを `groups` に設定する。`groups` はグループを<br />特定する整数のリストとする。通常、この操作はスーパユーザーしか利用できない | `None` |\n",
        "| `os.setpriority(which, who, priority)` | プログラムのスケジューリング優先度を設定する。`which` と `who` は `os.getpriority()` と同じ。`priority` は<br /> `-20` から `19` の整数値で、デフォルトの優先度は `0`。小さい数値ほど優先されるスケジューリングとなる | `None` |\n",
        "\n",
        "これらの関数は Windows では定義されない（呼び出すと `AttributeError` 例外が発生する）。"
      ],
      "metadata": {
        "id": "4ERA_zfzQ-jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getuid(), os.geteuid(), os.getgid(), os.getegid(), os.getgroups(), os.getpriority(os.PRIO_PROCESS, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNUBcQeSRo0s",
        "outputId": "213fe3a5-6cdd-4959-8d56-afeb4a589b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 0, [0], 0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "メモリ上でプロセスは次のような構成となる。\n",
        "\n",
        "  * **テキストセグメント**: プログラムそのものが格納される読み出し専用の領域\n",
        "  * **データセグメント**:\n",
        "      * **静的領域**: 定数やグローバル変数を格納する領域\n",
        "      * **ヒープ領域**: オブジェクトのように、実行するまで容量が未確定で一時的に必要とするデータを格納する領域\n",
        "  * **スタックセグメント**: 関数とその中に定義された変数を下から順に格納し、上から実行され取り出されていく領域。**スタック領域**ともいう。\n",
        "\n",
        "``` text\n",
        "             メモリマップ\n",
        "0xffffffff┏━━━━━━━━┓\n",
        "          ┃                ┃\n",
        "          ┃  スタック領域  ┃ スタックセグメント\n",
        "      SP→┃                ┃\n",
        "          ┣━━━━━━━━┫\n",
        "                   ↓ 自動拡張\n",
        "\n",
        "          ┏━━━━━━━━┓\n",
        "          ┃共有ライブラリ１┃\n",
        "          ┗━━━━━━━━┛\n",
        "          ┏━━━━━━━━┓\n",
        "          ┃共有ライブラリ２┃\n",
        "          ┗━━━━━━━━┛\n",
        "\n",
        "                   ↑ 自動拡張\n",
        "          ┣━━━━━━━━┫\n",
        "          ┃                ┃\n",
        "          ┃   ヒープ領域   ┃\n",
        "          ┃                ┃ データセグメント\n",
        "          ┠────────┨\n",
        "          ┃    静的領域    ┃\n",
        "          ┣━━━━━━━━┫\n",
        "          ┃                ┃\n",
        "      PC→┃                ┃ テキストセグメント\n",
        "          ┃                ┃ （読み出し専用）\n",
        "         0┗━━━━━━━━┛\n",
        "\n",
        "```\n",
        "\n",
        "ヒープ領域が不足すると、Python は `MemoryError` 例外を送出する。スタック領域が不足すると、Python はエラー（stack overflow）を出してインタープリターの実行を中断する。\n",
        "\n",
        "共有ライブラリは、ヒープ領域とスタック領域の間にある。どの番地に割り当てられるかは、システムに依存する。\n",
        "\n",
        "また、メモリとは別に、 CPU 内にはレジスタと呼ばれる記憶装置があり、そこにはスタック領域のどこを見ているかを指す**スタックポインタ**（SP）と、プログラムのどこを実行しているかを指す**プログラムカウンタ**（PC）が置かれている。プロセスは、メモリ上の構成と SP、PC を最小セットする。このデータの最小セットを**コンテキスト**（context）と呼ぶ。"
      ],
      "metadata": {
        "id": "JuCMYgN9WAWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### マルチプロセス ###"
      ],
      "metadata": {
        "id": "WHNaZW_eaY9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "同時に実行するプロセスが複数存在することを**マルチプロセス**（multiprocessing）という。マルチプロセスでも各プロセスにコンテキストが作られることに変わりはないから、各プロセスのメモリ空間は独立していてメモリ上のデータを共有することはない。\n",
        "\n",
        "1 つの CPU コアは 1 つのプロセスだけが利用できる。CPU コアが足りていれば、マルチプロセスは並列処理される。CPU コアが不足すれば、マルチプロセスは並行処理される。1 つの CPU コアで実行されるプロセスが切り替わることは**コンテキストスイッチ**（context switching）と呼ばれる。具体的には、CPU コアがあるプロセスを実行している最中に処理を中断して現在のプロセスのコンテキストを特定のメモリ領域などに保存し、別のプロセスのコンテキストを読み込んで処理を再開するということが行われる。コンテキストスイッチによるプロセスの切り替えは、人間には認識できないほどに高速に行われるため、複数のプロセスが同時に実行されているように感じられる。"
      ],
      "metadata": {
        "id": "A2K5FOgeaaCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### スレッド ###"
      ],
      "metadata": {
        "id": "ZRqVQbUbeXFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 つのアプリケーション内で複数のプロセスを起動し並列処理を行うことも可能である。しかしながら、各プロセスは独立のメモリ空間が割り当てられるので、起動時にそれなりのオーバーヘッドが発生する。また、プロセス間でデータを交換するには特別な仕組みが必要となる。\n",
        "\n",
        "そこで、1 つのプロセス内で並列処理を行う仕組みが作られた。このとき各 CPU コアを占有する一連の処理の流れのことを**スレッド**（thread）と呼ぶ。つまり、スレッドはプロセスより細かい CPU コア利用の最小単位とされるものである。プロセス起動時には必ず 1 個のスレッドが生成されるので、1 個のプロセスには最小限 1 個のスレッドが存在する。プロセス起動時に生成されるスレッドを**メインスレッド**と呼ぶ。メインスレッドから枝分かれするスレッドが存在することを**マルチスレッド**（multithread）といい、マルチスレッドでないものは**シングルスレッド**（singlethread）という。枝分かれしたスレッドからさらに枝分かれすることもできる。\n",
        "\n",
        "``` text\n",
        "            \n",
        "  ┏━━━━━━━━━━┓     ┏━━━━━━━━━━━━━━┓\n",
        "  ┃（シングルスレッド）┃     ┃     （マルチスレッド）     ┃\n",
        "  ┃    ┌────┐    ┃     ┃        ┌────┐        ┃\n",
        "  ┃    │ 処理Ａ │    ┃     ┃        │ 処理Ａ │        ┃\n",
        "  ┃    └────┘    ┃     ┃        └────┘        ┃\n",
        "  ┃         ↓         ┃     ┃         ↙        ↘         ┃\n",
        "  ┃    ┌────┐    ┃     ┃ ┌────┐  ┌────┐ ┃\n",
        "  ┃    │ 処理Ｂ │    ┃     ┃ │ 処理Ｂ │  │ 処理Ｄ │ ┃\n",
        "  ┃    └────┘    ┃     ┃ └────┘  └────┘ ┃\n",
        "  ┃         ↓         ┃     ┃      ↓            ↓      ┃\n",
        "  ┃    ┌────┐    ┃     ┃ ┌────┐  ┌────┐ ┃\n",
        "  ┃    │ 処理Ｃ │    ┃     ┃ │ 処理Ｃ │  │ 処理Ｅ │ ┃\n",
        "  ┃    └────┘    ┃     ┃ └────┘  └────┘ ┃\n",
        "  ┗━━━━━━━━━━┛     ┗━━━━━━━━━━━━━━┛\n",
        "```\n",
        "\n",
        "スレッドは、メモリのスタック領域とスタックポインタとプログラムカウンタから構成される。ヒープ領域と静的領域は同じものをスレッド間で共有する。つまり、処理を行う関数などの流れを作成して、変数などのデータは共有するという仕組みである。スレッドの構成はプロセスの構成より小さいため、スレッド生成時に発生するオーバーヘッドはプロセス生成時のものより少ない。また、共有するデータについてはスレッド間でデータ交換を行う必要がない。"
      ],
      "metadata": {
        "id": "uYjNDZwmqaX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 論理コア ###"
      ],
      "metadata": {
        "id": "2w9H4GOfsIBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "スレッドは CPU コアを占有するから、並列処理が可能なスレッドの数は物理的に存在するコア数に制限されるはずである。しかしながら、この制限を緩和する技術として**同時マルチスレッディング**（Simultaneous Multi-Threading; **SMT**）が存在する。ハイパースレッディング・テクノロジー（Hyper-Threading Technology）は、インテルの SMT 実装に対する同社の登録商標である。\n",
        "\n",
        "SMT の概要は以下のとおり。物理的に存在する 1 個の CPU コアは複数の回路から構成され、それらは I/O 制御、整数演算、浮動小数点数演算などの役割を持つ。個々のスレッドは、CPU コア内の全ての回路を使うわけではないことが多い。たとえば、フィボナッチ数を調べるプログラムは整数演算ばかり行うスレッドを生成し、そのスレッドの処理中は浮動小数点数演算を行う回路が使われない。そこで、使用されない回路を他のスレッドに割り当て、2 つのスレッドが同時に実行するようにしたものが SMT である。各スレッドからは SMT は隠蔽され、2 つの CPU コアが動作しているかのように見える。このようにソフトウェア側から見える疑似的な CPU コアを**論理コア**と呼ぶ。SMT が有効な場合、1 スレッド - 1 論理コアという対応になる。\n",
        "\n",
        "`os` モジュールは、論理コア数に関する関数を提供している:\n",
        "\n",
        "| 関数 | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `os.cpu_count()` | システム全体で利用可能な論理コア数を返す。論理コア数を取得できなかった時 `None` を返す | `int` &vert; `None` |\n",
        "| `os.process_cpu_count()` | 現在実行中のプロセスが使用できる論理コア数を返す。論理コア数を取得できなかった時 `None` を返す<br />（Python 3.13 で追加） | `int` &vert; `None` |\n",
        "\n",
        "システム全体で利用可能な論理コア数の全てを Python のプロセスで使用できるとは限らない。`os.process_cpu_count()` 関数は、CPU リソースを動的に確認でき、並列処理を行う際に、どの程度の並列を使うべきか調整することができる。\n",
        "\n",
        "``` shell\n",
        ">>> import os\n",
        ">>> os.cpu_count()\n",
        "12\n",
        ">>> os.process_cpu_count()\n",
        "12\n",
        "```\n",
        "\n",
        "また、標準ライブラリの `multiprocessing` パッケージも `cpu_count()` 関数を提供する。これも論理コア数を返すが、論理コア数を取得できなかった時 に` NotImplementedError` 例外を送出する。"
      ],
      "metadata": {
        "id": "nKtYfh4QeX0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "multiprocessing.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4elonVsYNPB",
        "outputId": "22e87a44-2729-45db-b6d6-0c025e7e1ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### タスク ###"
      ],
      "metadata": {
        "id": "3aM7MBSAjMaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 つのまとまった処理または命令を**タスク**（task）と呼ぶ。どの大きさでまとめるとタスクと言えるという定義はない。タスクは、文脈によって、スレッド内の命令の集合を指していたり、スレッドそのものを指していたり、プロセスを指していたり、プロセスの集合を指していたりする。\n",
        "\n",
        "マルチプロセスは、**マルチタスク**（multitasking）とも呼ばれる。なお、マルチタスクは日本において NEC の登録商標である。"
      ],
      "metadata": {
        "id": "3RSSTBahjNjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "threading\n",
        "---------"
      ],
      "metadata": {
        "id": "z9GFqonlK6Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "プロセスとスレッドは OS によって管理される。OS のスレッド周りの API に対する標準の Python インターフェースとしては、`_thread` モジュールと `threading` モジュールがある。`_thread` は OS の API に近い低レベルのインターフェースを提供していて、`threading` は `_thread` の上に構築された高レベルなインターフェースを提供している。よって、通常は `threading` を使う。"
      ],
      "metadata": {
        "id": "FyPbAnsKZl_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### インスタンス化 ###"
      ],
      "metadata": {
        "id": "LbebtPn4ZodI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`threading` モジュールは、スレッドを `threading.Thread` オブジェクトとして扱う。コンストラクタは次のとおり:\n",
        "\n",
        "``` python\n",
        "threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)\n",
        "```\n",
        "\n",
        "コンストラクタは常にキーワード引数を使って呼び出さなければならない。各引数は以下のとおり:\n",
        "\n",
        "| 引数 | 意味 |\n",
        "|:---|:---|\n",
        "| `group` | `None` にする必要がある。この引数は将来 `ThreadGroup` クラスが実装されるときの拡張用に予約されている |\n",
        "| `target` | インスタンスの `run()` メソッドによって起動される呼び出し可能オブジェクトを指定する。デフォルトでは何も呼び出さないことを示す `None` になってい<br />る |\n",
        "| `name` | スレッドの名前を指定する。値はインスタンスの `name` 属性で参照できる。デフォルトの `name` 属性は、`target` 引数が指定されない場合に `Thread-N`（`N`<br /> は小さな 10 進数）となり、`target` 引数が指定された場合に `Thread-N (target)` という形式でユニークな名前が構成される |\n",
        "| `args` | `target` を呼び出すときの位置引数をリストかタプルで指定する。デフォルトは `()` |\n",
        "| `kwargs` | `target` を呼び出すときのキーワード引数を辞書で指定する。デフォルトは `{}` |\n",
        "| `daemon` | このスレッドがデーモン（メインメモリ上に常駐してバックグラウンドで動作するプログラム）であるか否かを示すブール値を設定する。値はインスタンスの<br /> `daemon` 属性で参照できる。`None`（デフォルト）の場合、`daemon` 属性は現在のスレッドから継承される |\n",
        "\n",
        "`threading.Thread` オブジェクトの識別には、`name` 属性（読み書き可能なプロパティ）または `ident` 属性（読み取り専用プロパティ）が使える。`ident` 属性はスレッドが開始されていなければ `None` で、開始されていれば非ゼロの整数が格納されている。\n",
        "\n",
        "`threading.Thread` オブジェクトのメソッドは次のとおり:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `start()` | スレッドを開始し、`run()` メソッドを実行する。このメソッドはオブジェクトあたり一度だけ呼び出すことができる | `None` |\n",
        "| `run()` | このスレッド内で `target` を呼び出す | `None` |\n",
        "| `join(timeout=None)` | スレッドが終了するまで待機する。`timeout` に浮動小数点数を指定した場合は、このメソッドは `timeout` 秒でタイムアウトする（次<br />のコードに進む）。現在のスレッドに対してこのメソッドを呼び出そうとすると `RuntimeError` 例外を送出する | `None` |\n",
        "| `is_alive()` | スレッドが動作中の場合に `True` を返し、そうでない場合に `False` を返す。`join()` がタイムアウトしたかどうかはこのメソッドで<br />確認できる | `bool` |\n",
        "\n",
        "`threading` モジュールは、ロードされると暗黙のうちにメインスレッド（Python インタープリターが起動したスレッド）に対応するオブジェクトを作成する。このオブジェクトは、`threading.Thread` クラスを継承する `threading._MainThread` クラスのインスタンスであり、`name` 属性が `'MainThread'` になっている。\n",
        "\n",
        "``` python\n",
        "threading.current_thread()\n",
        "```\n",
        "\n",
        "この関数は、関数を呼び出している処理のスレッドに対応する `threading.Thread` オブジェクトを返す。関数を呼び出している処理のスレッドが `threading` モジュールで生成したものでない場合、限定的な機能しかもたないダミースレッドオブジェクトを返す。\n",
        "\n",
        "``` python\n",
        "threading.enumerate()\n",
        "```\n",
        "\n",
        "この関数は、現在、アクティブな `threading.Thread` オブジェクト全てのリストを返す。リストには、終了したスレッドとまだ開始していないスレッドは入らない。しかし、メインスレッドは、たとえ終了しても、常に結果に含まれる。\n",
        "\n",
        "次のコードは、1 秒ごとに 3 回まで `print()` 関数で出力する `run()` 関数を 2 つのスレッドで実行する。"
      ],
      "metadata": {
        "id": "z_7UBb7tK6vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def run(base):\n",
        "    for i in range(3):\n",
        "        time.sleep(1.0)\n",
        "        print(\"{}: {}\".format(threading.current_thread().name, base + i))\n",
        "\n",
        "\n",
        "def main(*args):\n",
        "    print(f\"started at {time.strftime('%X')}\")\n",
        "    for t in args:\n",
        "        t.start()\n",
        "    for t in args:\n",
        "        t.join()\n",
        "    print(f\"finished at {time.strftime('%X')}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    t1 = threading.Thread(target=run, name=\"t1\", args=(10,))\n",
        "    t2 = threading.Thread(target=run, name=\"t2\", args=(20,))\n",
        "    main(t1, t2)"
      ],
      "metadata": {
        "id": "U-d7JS84ioGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536f016f-4263-46e6-fadd-32eca061515f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "started at 02:39:45\n",
            "t1: 10\n",
            "t2: 20\n",
            "t1: 11\n",
            "t2: 21\n",
            "t1: 12\n",
            "t2: 22\n",
            "finished at 02:39:48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "名前が `t1` と `t2` の 2 つのスレッドが交替で実行されていることを確認できる。2 つのスレッドを開始してから終了するまでの時間が 3 秒なので、並列処理が行われている。\n",
        "\n",
        "次のコードは、リストを 20 万回 `append()` する `run()` 関数を 2 個のスレッドで実行し、その後に同関数を 1 個のスレッドで実行する。"
      ],
      "metadata": {
        "id": "Hvm8Cj0RlquW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def run():\n",
        "    a = []\n",
        "    for i in range(20000000):\n",
        "        a.append(0)\n",
        "\n",
        "\n",
        "def main(*args):\n",
        "    print(f\"started at {time.strftime('%X')}\")\n",
        "    for t in args:\n",
        "        t.start()\n",
        "    for t in args:\n",
        "        t.join()\n",
        "    print(f\"finished at {time.strftime('%X')}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    t1 = threading.Thread(target=run)\n",
        "    t2 = threading.Thread(target=run)\n",
        "    t3 = threading.Thread(target=run)\n",
        "    print(\"2スレッド-----------\")\n",
        "    main(t1, t2)\n",
        "    print(\"1スレッド-----------\")\n",
        "    main(t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn-SaiYckmeE",
        "outputId": "27428e20-8430-4d1c-aa04-696ae7ad6358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2スレッド-----------\n",
            "started at 02:39:48\n",
            "finished at 02:39:54\n",
            "1スレッド-----------\n",
            "started at 02:39:54\n",
            "finished at 02:39:57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 スレッドの場合の処理時間が 1 スレッドの場合の 2 倍になっていることから、2 スレッドは並列処理されていないことがわかる。\n",
        "\n",
        "2 つのコードの実行結果の違いはどのような理由によるものであろうか。"
      ],
      "metadata": {
        "id": "WxK1PZBvmnfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIL ###"
      ],
      "metadata": {
        "id": "t75xhOyW-rVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実は、 CPython では、マルチスレッドがあっても CPU コアを占有できるのはロックを保持する単一のスレッドに制限される。このロックを**グローバルインタープリターロック**（Global Interpreter Lock）、略して GIL（ギル）と呼ぶ。GIL の獲得と解放により、動作するスレッドが切り替わる。つまり、**CPython のマルチスレッドは並行処理となる**。ただし、GIL は Python で書かれた処理についての制限であり、モジュールが利用する C などで書かれた処理は GIL の制限を受けず、並列処理が可能である。\n",
        "\n",
        "CPython に GIL が存在する理由は、C における「データ競合」を回避するためである。C では、1 つのプロセス内の 2 つ以上のスレッドがメモリ上の同じ場所に同時にアクセスすることによってプログラムが C の規格で未定義の振る舞いをする現象があり、この現象を**データ競合**（data race）と呼ぶ。データ競合はソフトウェアセキュリティの脆弱性につながる可能性がある。データ競合を回避するには、メモリへのアクセスを制御（ロック）する必要がある。ところが、Python 言語の処理系の実装では、ロックが必須なメモリアクセスが多すぎて、パフォーマンスが大きく低下することがわかっている。そこで、個別のメモリアクセスを制御するのではなく、スレッドの動作全体を制御する GIL が導入された。\n",
        "\n",
        "データ競合は C に限らない現象であるが、その定義や扱いはプログラミング言語ごとに異なる。このため、GIL の存在は Python 言語の仕様として要求されていない。実際、Java による Python 実装（Jython）には GIL は存在しない。しかしながら、最も広く使用されている Python 実装は CPython なので、事実上マルチスレッド Python プログラムは並行処理と考えなければならない。\n",
        "\n",
        "シングルスレッドでは、データ競合は発生しないので、GIL の解放は起こらないようになっている。つまり、シングルスレッドの場合、スレッドは何事もなく最後まで実行される。\n",
        "\n",
        "マルチスレッドの場合、GIL の獲得と解放がおおむね以下のように行われる。\n",
        "\n",
        "  * あるスレッドが GIL を獲得すると、それだけが CPU コアを占有する。他のスレッドは（実行中であっても）休止する。\n",
        "  * GIL を保持するスレッドは、I/O 操作が発生したら、自発的に全てのスレッドに通知を行う。これを受けて、他のスレッドが GIL を獲得する。\n",
        "  * 休止中のスレッドは、タイムアウト（デフォルトで 5 ミリ秒後）になったら C のグローバル変数 `gil_drop_request` の値（デフォルト値は 0）を 1 に設定する。`gil_drop_request` の値が 1 の場合、GIL を保持するスレッドは全てのスレッドに通知を行う。これを受けて他のスレッドが GIL を獲得すると、GIL を解放したスレッドに通知し、`gil_drop_request` の値は 0 に戻される。\n",
        "  * スレッドの切り替え時にはコンテキストスイッチが行われるので、スレッドが GIL を解放した後、再び GIL を獲得して実行する場合、前回の続きから再開する。\n",
        "\n",
        "`sys` モジュールは、GIL のタイムアウト時間を取得、設定する関数を提供している。\n",
        "\n",
        "| 関数 | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `sys.getswitchinterval()` | GIL のタイムアウト時間を返す | `float` |\n",
        "| `sys.setswitchinterval(interval)` | GIL のタイムアウト時間を `interval`（浮動小数点数）に指定する | `None` |"
      ],
      "metadata": {
        "id": "0jxM-14u-r_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.getswitchinterval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13_emLG9ndHH",
        "outputId": "3ceffea2-42a8-418d-878c-b0cd46532493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIL はタイムアウトしていなければ「I/O 操作発生」によってのみ解放されるわけであるが、I/O 操作を行う処理のことを **I/O バウンド**（I/O bound）と呼ぶ。システム時刻の問い合わせ、標準入出力やファイルの読み書き、ネットワーク通信はすべて I/O バウンドな処理である。\n",
        "\n",
        "一方、I/O 操作を伴わない処理（論理演算や整数演算、浮動小数点数演算など）のことは **CPU バウンド**（CPU-bound）と呼ぶ。Python オブジェクトの操作は CPU バウンドな処理である。\n",
        "\n",
        "2 種類のマルチスレッド処理で GIL の影響の違いは次のように整理できる。\n",
        "\n",
        "  * I/O バウンドな処理:  \n",
        "I/O 操作が行われるたびにスレッドが切り替わる。遅いネットワーク通信などを待たずに他の処理に移ることができるため効率がよい。\n",
        "  * CPU バウンドな処理:  \n",
        "計算の途中でもタイムアウトによりスレッドが切り替わるため、余計に計算コストがかかり遅くなる。\n",
        "\n",
        "`threading.Thread` インスタンス化の例として示した 2 つのコードのうち、1 番目のものについては、`run()` 関数内での `time.sleep()` 関数の実行と `print()` 関数の実行はともに I/O バウンドであり、I/O 操作が発生して下図のようにスレッドが切り替わるため、2 つのスレッドが交替で実行され、スリープ時間で処理時間が 2 倍になることはなかったわけである。つまり、I/O バウンドな処理では並列処理が実現される。この並列処理は CPU コア数以上にスケールできる（CPU コアは常に 1 個しか利用されない）。\n",
        "\n",
        "``` text\n",
        "           ┌─────────────────────────────────────────────────────┐\n",
        "           │      ┌───────┐                                            ┌─────┐                        │\n",
        "t1 thread: │run() │ time.sleep() │I/O 操作 ………………[スリープ]……………… │ print()  │I/O 操作   （以下省略） │\n",
        "           │      └───────┘              タイムアウト  タイムアウト    └─────┘                        │\n",
        "           └─────────────────────────────────────────────────────┘\n",
        "                                    ↓      ↑           ↓    ↑      ↓     ↑                ↓      ↑\n",
        "           ┌─────────────────────────────────────────────────────┐\n",
        "           │              ┌───────┐          タイムアウト  タイムアウト   ┌─────┐                     │\n",
        "t2 thread: │run()         │ time.sleep() │I/O 操作 …………[スリープ]………………│ print()  │I/O 操作 （以下省略）│\n",
        "           │              └───────┘                                       └─────┘                     │\n",
        "           └─────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "2 番目のコードについては、`run()` 関数を実行するスレッドは CPU バウンドであり、2 スレッドの場合はタイムアウトでスレッドが切り替わる並行処理が行わる。このため、1 スレッドだけで計算する場合より処理時間が 2 倍以上長くなったのである。\n",
        "\n",
        "では、I/O バウンドなスレッドと、CPU バウンドなスレッドが同時に走っている場合はどうなるのであろうか。スレッドは優先度を持たないため、どちらが先に GIL を獲得するのかはわからないのであるが、獲得順によって処理の効率は次のように異なる:\n",
        "\n",
        "  * I/O バウンドなスレッドが先に GIL を獲得する場合、I/O 操作発生で CPU バウンドなスレッドに切り替わり、I/O の待機中に CPU バウンドな処理が進行することになるので、効率が良い。\n",
        "  * CPU バウンドなスレッドが先に GIL を獲得する場合、タイムアウトになるまで CPU バウンドな処理が進行し、その後に I/O バウンドなスレッドに切り替わって I/O 待ちに入るということになるので、I/O 待ちの待機時間の分だけ実行時間が長引くことになる。\n",
        "\n",
        "2 つ目のケースように非効率な形で GIL が獲得される現象を **Convoy Effect** という。Convoy Effect が発生することを防ぐ方法はない。"
      ],
      "metadata": {
        "id": "om-Wbi1fECRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIL の無効化 ###"
      ],
      "metadata": {
        "id": "-42lvC3zO132"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python 3.13 では、実験的な機能として、GIL を無効化した CPython をビルドできるようになった。\n",
        "\n",
        "GIL を無効化したマルチスレッドなら、CPU バウンドなスレッドも並列処理が可能となるから、マルチコア CPU を活かすことができ、パフォーマンス向上が期待できる。\n",
        "\n",
        "しかし、GIL の無効化は、以下の問題があることに注意する。\n",
        "\n",
        "  * GIL 除去によるパフォーマンス低下を最低限にするための手法が導入されているものの、全てのケースでマルチスレッドのパフォーマンスが改善されるわけではない。\n",
        "  * 「I/O 操作発生」によるスレッド切り替えが行われなくなるので、I/O バウンドな処理の並列化は CPU コア数以上にスケールできなくなる。\n",
        "  * シングルスレッドでは逆に性能が低下する。\n",
        "  * GIL に依存するライブラリでは不具合が生じる。\n",
        "\n",
        "GIL を無効化した CPython バイナリを**フリースレッドバイナリ**（free-threaded binary）と呼ぶ。\n",
        "\n",
        "公式の Windows 用 Python インストーラーはフリースレッドバイナリを含んでおり、「Customize installation」を選択して進むと表示される「Advanced Options」の中の「Download free-threaded binaries」をチェックすることで、フリースレッドバイナリがインストールされる。フリースレッドバイナリは、`python3.13t` のように `t` を付加したファイル名でインストールされるので、通常の Python と共存してインストールできる。\n",
        "\n",
        "Python ランチャーでフリースレッドバイナリを指定するには、次のように実行する:\n",
        "\n",
        "``` shell\n",
        "py -3.13t\n",
        "```\n",
        "\n",
        "フリースレッドバイナリを使う場合でも、Python 言語の機能は通常の Python と全く同じであり、特別な構文が導入されるわけではない。\n",
        "\n",
        "フリースレッドバイナリでも、環境変数 `PYTHON_GIL` を `1` に設定すると GIL が有効になる。`PYTHON_GIL` を `0` に設定すると GIL が無効になる。\n",
        "\n",
        "フリースレッドバイナリでは、次の関数が使える。\n",
        "\n",
        "| 関数 | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `sys._is_gil_enabled()` | GIL が有効になっている場合は `True` を返し、無効になっている場合は `False` を返す | `bool` |"
      ],
      "metadata": {
        "id": "HjkDnQ_rO2d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### デーモンスレッド ###"
      ],
      "metadata": {
        "id": "HWv0f_dlw034"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "コンストラクタの `daemon` 引数またはインスタンスの `daemon` プロパティを `True` に設定したスレッドはデーモンとして稼働する。デーモンスレッドは、メインスレッドを含めてデーモンでないスレッドがすべて終了すると停止する。\n",
        "\n",
        "次のコードでは、`t2` スレッドで実行される `run2()` 関数はグローバル変数 `request`に値を代入して終了する。`t1` スレッドはデーモンとして稼働し、そこで実行される `run1()` 関数は無限ループを実行する。その無限ループの中で、`request` 変数に値が代入されたらその値を出力する。\n",
        "\n",
        "``` python\n",
        "import time\n",
        "import threading\n",
        "\n",
        "request = None\n",
        "\n",
        "\n",
        "def run1():\n",
        "    global request\n",
        "    while True:\n",
        "        if request is None:\n",
        "            time.sleep(0.2)\n",
        "            print(\"{}: running...\".format(threading.current_thread().name))\n",
        "        else:\n",
        "            print(\"{}: {} is received\".format(threading.current_thread().name, request))\n",
        "            request = None\n",
        "\n",
        "\n",
        "def run2():\n",
        "    global request\n",
        "    time.sleep(0.5)\n",
        "    request = \"hoge\"\n",
        "    time.sleep(0.2)\n",
        "    print(\"{}: end\".format(threading.current_thread().name))\n",
        "\n",
        "\n",
        "def main():\n",
        "    t1 = threading.Thread(target=run1, name=\"t1\", daemon=True)\n",
        "    t2 = threading.Thread(target=run2, name=\"t2\")\n",
        "    t1.start()\n",
        "    t2.start()\n",
        "    t2.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"{}: end\".format(threading.current_thread().name))\n",
        "```\n",
        "\n",
        "このコードの実行結果は以下のようになる。\n",
        "\n",
        "``` shell\n",
        "t1: running...\n",
        "t1: running...\n",
        "t1: running...\n",
        "t1: hoge is received\n",
        "t2: end\n",
        "MainThread: end\n",
        "```\n",
        "\n",
        "`run1()` 関数の無限ループは、break 文がないにもかかわらずメインスレッドの終了後に停止するため、プログラムはちゃんと終了することがわかる。なお、`main()` 関数の最後に `t1.join()` を加えると、`t1.join()` は `run1()` 関数の終了を待つのでプログラムはいつまでたっても終了しなくなることに注意する。"
      ],
      "metadata": {
        "id": "kbRxo5Q6w1oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 競合状態 ###"
      ],
      "metadata": {
        "id": "gUMmXxB9fXJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチスレッドの実行順序やタイミングによって異なる結果が生まれる状態を**競合状態**（race condition）という。競合状態とデータ競合は、似て非なる概念である。GIL の存在によって Python ではデータ競合は発生しないが、競合状態は起こり得る。\n",
        "\n",
        "たとえば、次のコードでは、`counter()` 関数を動かすスレッドを 3 つ作成している。`counter()` 関数では、引数に渡された辞書 `data` に対して `data['n']` の値（初期値 0）を 1 増加する処理を行うが、3 つのスレッドが終了した時点で `data['n']` の値は 3 になるとは限らない。"
      ],
      "metadata": {
        "id": "Ez72Znl3fX4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def counter(data):\n",
        "    n = data['n']\n",
        "    time.sleep(0.2)\n",
        "    data['n'] = n + 1\n",
        "    print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    threads = [threading.Thread(target=counter, name=f\"t{i}\", args=(data,)) for i in range(3)]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnXqR80EIt_u",
        "outputId": "18840f43-ffa3-452e-de8b-003b335c602e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t0: data['n']=1\n",
            "t1: data['n']=1\n",
            "t2: data['n']=1\n",
            "MainThread: data['n']=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "最初に GIL を獲得したスレッドで `counter()` 関数内のローカル変数 `n` に `data['n']` の初期値 0 を代入し、直後に `time.sleep()` を呼び出す。この時点でスレッドが切り替わり、別のスレッドでもローカル変数 `n` に `data['n']` の初期値 0 が代入される。もし `time.sleep()` の呼び出しまでに 3 つのスレッドが 1 回ずつ実行されていれば、各スレッドでローカル変数 `n` の値は 0 になっている。この場合、その後のコンテキストスイッチにより、今度は各スレッドで `data['n']` に `0 + 1` の計算結果値が代入されることになるため、3 つのスレッドが終了した時点で `data['n']` の値は 3 になるとは限らないわけである（1 になるとも 2 になるとも限らない）。\n",
        "\n",
        "競合状態での結果は、「プログラマーがそう書いたからそう動いている」だけであり、プログラミング言語で未定義の動作が起こっているわけではない。ただ、その結果がプログラマーの意図に反するものであればバグと言える。"
      ],
      "metadata": {
        "id": "7Ey5nzADV0nK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### スレッドの同期 ###"
      ],
      "metadata": {
        "id": "MkKsc1VVUbNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "複数の処理について、処理の進行を待ち合わせることを**同期**（synchronous）という。同期でないものは**非同期**（asynchronous）という。マルチスレッドまたはマルチプロセスのプログラミングにおいて、異なるスレッドやプロセス間で同期を取るための制御機構を**同期プリミティブ**（synchronization primitive）という。\n",
        "\n",
        "マルチスレッドの競合状態を、複数人でオールを漕いでボートが進む状態に例えるなら、漕ぎ手がスレッド、ボートがプログラムであり、漕ぎ手のタイミングを合わせないとボートが正しい方向に進まないように、スレッド間で同期を取らないとプログラムが正しく動作しないのである（画像は[いらすとや](https://www.irasutoya.com/2012/07/blog-post_3963.html)より）。同期プリミティブは、漕ぎ手のタイミング合わせに使われる掛け声や笛に相当する。\n",
        "\n",
        "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhkr3KmVJffiUV0pebpKjpZLEVi7KVbmRbH7y4BBFZHkee5Yq8TtT7kDQxdB8VnrJ6wMFOsuwB1Lm9ER2GilJ0XIb28mHwxAz3sOSJLz48r9uGwd5BjoQcUoLf3FC1sTxSQ7-uA8Knx9D8/s800/olympic21_boat_4.png\" width=\"400\">\n",
        "\n",
        "`threading` モジュールは、以下の同期プリミティブをサポートする。\n",
        "\n",
        "  * ミューテックス（ロック）\n",
        "  * セマフォ\n",
        "  * イベント（Event）\n",
        "  * コンディション（Condition）── 一般には条件変数（Condition Variables）と呼ばれる\n",
        "  * バリア（Barrier）"
      ],
      "metadata": {
        "id": "ySdWRU5JUcCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 直列化とミューテックス ###"
      ],
      "metadata": {
        "id": "d2j7FtuLd1HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "スレッドを列に並ばせるように待機させ、一つずつ順番に実行させるような同期の取り方を**逐次化**あるいは**直列化**（serialize）と呼ぶ。共有データを扱う場面での競合状態では、直列化を行わないとバグが発生する可能性がある。\n",
        "\n",
        "一方、あるスレッドが共有データなどの資源を利用している間は、他のスレッドが同じものにアクセスすることを制限もしくは禁止する仕組みのことを**排他制御**という。とくに、1 つのスレッドが資源を占有し、他のスレッドからのアクセスを禁止するという排他制御の方式は**ロック**（lock）と呼ばれる。GIL もロックの一種である。ロック方式は、代表的な排他制御なので、排他制御を意味する英語 mutual exclusion を略した形で**ミューテックス**（mutex）とも呼ばれる。ミューテックスは、直列化の手法として利用される。\n",
        "\n",
        "``` python\n",
        "threading.Lock()\n",
        "```\n",
        "\n",
        "これはロックを返す。ただし、実際には `threading.Lock` というクラスが定義されているわけではなく、これは `_thread.get_ident()` 関数の別名であることに注意すること。\n",
        "\n",
        "ロックのメソッドは次のとおり。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `acquire(blocking=True, timeout=-1)` | ロックの獲得を試み、実際に獲得すると `True` を、獲得できなかったとき `False` を返す。他のスレッドが既に<br />ロックを獲得している場合、`blocking` と `timeout` の指定によってメソッドの挙動が異なる。`blocking` が<br /> `True`（デフォルト）なら、ロックが解放されるまで待機する。`blocking` が `False` なら、直ちに `False` を返し<br />待機しない。`timeout` に正の浮動小数点が設定された場合、`timeout` 秒だけ待機する。`blocking` が `False` <br />の場合に `timeout` を指定することは禁止される | `bool` |\n",
        "| `release()` | ロックを解放する。これはロックを獲得したスレッドだけでなく、任意のスレッドから呼ぶことができる | `None` |\n",
        "\n",
        "ロックはコンテキストマネージャーとして使用できる。`acquire()` メソッドは with ブロックに入るときに呼び出され、`release()` メソッドはブロックを終了するときに呼び出される。したがって、次のコード片\n",
        "\n",
        "``` python\n",
        "with some_lock:\n",
        "    # do something...\n",
        "```\n",
        "\n",
        "これは、以下と同じ。\n",
        "\n",
        "``` python\n",
        "some_lock.acquire()\n",
        "try:\n",
        "    # do something...\n",
        "finally:\n",
        "    some_lock.release()\n",
        "```\n",
        "\n",
        "次のコードは、競合状態のコード例にロックを追加したものである。"
      ],
      "metadata": {
        "id": "rFUwXmWvd19K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def counter(data, lock):\n",
        "    with lock:  # ロックの獲得と解放\n",
        "        n = data['n']\n",
        "        time.sleep(0.2)\n",
        "        data['n'] = n + 1\n",
        "        print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    lock = threading.Lock()  # ロックを作成\n",
        "    threads = [threading.Thread(target=counter, name=f\"t{i}\", args=(data, lock)) for i in range(3)]  # ロックを渡す\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLQf4AIBtJz_",
        "outputId": "f6493bcb-6f6f-4fee-b1c9-1d34dcef61d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t0: data['n']=1\n",
            "t1: data['n']=2\n",
            "t2: data['n']=3\n",
            "MainThread: data['n']=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`data['n']` の値は、各スレッドが動かす `counter()` 関数により確実に 1 増加され、3 つのスレッドが終了した時点で 3 になる。この実行結果から、`counter()` 関数内の with 文でロックを獲得したスレッドが with 文の本体を処理している間、スレッド切り替えが行われず、このため `data['n']` に対する操作が直列化されていることがわかる。\n",
        "\n",
        "一方、ロックの解放を待つスレッドは、待機中に別の処理ができれば効率的である。この場合、ロックの `acquire()` メソッドを引数 `blocking=False` として呼び出すと、ロックを獲得できなければ待機せず直ちに `False` を返すことを利用する。\n",
        "\n",
        "次のコードは、前のコードに以下の変更を加えたものである。\n",
        "\n",
        "  * `counter()` 関数は、無限の while ループを使って、ロックを獲得できれば `data['n']` の値を 1 増加してロック解放後にループを終了するが、ロックを獲得できない間は別の作業（時刻の表示）をする。"
      ],
      "metadata": {
        "id": "dvrH6wrBHJK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def counter(data, lock):\n",
        "    while True:\n",
        "        if lock.acquire(blocking=False):\n",
        "            print(f\"{threading.current_thread().name}: ロックを獲得した\")\n",
        "            n = data['n']\n",
        "            time.sleep(0.2)\n",
        "            data['n'] = n + 1\n",
        "            print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "            lock.release()\n",
        "            break\n",
        "        else:\n",
        "            print(f\"{threading.current_thread().name}: {time.strftime('%X')}\")\n",
        "            time.sleep(0.2)\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    lock = threading.Lock()  # ロックを作成\n",
        "    threads = [threading.Thread(target=counter, name=f\"t{i}\", args=(data, lock)) for i in range(3)]  # ロックを渡す\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbZtzX1xWKvp",
        "outputId": "c01bae30-a87f-44ba-bb2e-a2a5addcbd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t0: ロックを獲得した\n",
            "t1: 02:39:57t2: 02:39:57\n",
            "\n",
            "t0: data['n']=1\n",
            "t2: ロックを獲得した\n",
            "t1: 02:39:58\n",
            "t2: data['n']=2\n",
            "t1: ロックを獲得した\n",
            "t1: data['n']=3\n",
            "MainThread: data['n']=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "実行結果から、あるスレッドがロックを保持している間も、他のスレッドは待機せずに時刻表示処理を行っていることがわかる。このように、ロックの獲得で待機しないことを**ノンブロッキング**（non-blocking）であるという。"
      ],
      "metadata": {
        "id": "LtysgRVIisvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### デッドロック ###"
      ],
      "metadata": {
        "id": "ygLjYhYakGTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**デッドロック**（deadlock）とは、2 つ以上のスレッド（あるいはプロセス）が互いに待機しあってしまい、結果としてどの処理も先に進めなくなってしまうことをいう。\n",
        "\n",
        "以下のコードは、デッドロックを発生させる簡単な例である。\n",
        "\n",
        "``` python\n",
        "import time\n",
        "import threading\n",
        "\n",
        "\n",
        "def worker1(data, lock1, lock2):\n",
        "    with lock1:\n",
        "        n = data['n']\n",
        "        time.sleep(0.2)\n",
        "        with lock2:\n",
        "            m = data['m']\n",
        "            data[\"n\"] = n - m\n",
        "            print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "def worker2(data, lock1, lock2):\n",
        "    with lock2:\n",
        "        m = data['m']\n",
        "        time.sleep(0.2)\n",
        "        with lock1:\n",
        "            n = data['n']\n",
        "            data['m'] = m + n\n",
        "            print(f\"{threading.current_thread().name}: {data['m']=}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0, 'm': 0}\n",
        "    lock1 = threading.Lock()\n",
        "    lock2 = threading.Lock()\n",
        "    threads = [\n",
        "        threading.Thread(target=worker1, name=\"t1\", args=(data, lock1, lock2)),\n",
        "        threading.Thread(target=worker2, name=\"t2\", args=(data, lock1, lock2)),\n",
        "    ]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    print(f\"{threading.current_thread().name}: {data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "このコードでは、2 つの共有データの要素 `data['n']` と `data['m']` に対するアクセスを別々に制御するため、2 つのロック `lock1` と `lock2` を作成する。`worker1()` 関数は `lock1` を獲得した後、`lock2` を獲得しようとする。同様に、`worker2()` 関数は `lock2` を獲得した後、`lock1` を獲得しようとする。ロックの獲得が循環的になっているため、いつまでも条件を満たせず、デッドロックが発生する。\n",
        "\n",
        "この問題は、**食事する哲学者の問題**として知られる。円卓に麺と箸 1 本が交互に並べられた状況で、席に着いた哲学者はまず左側の箸を取ってから次に右側の箸を取ってよいという制約があると仮定する。全員が同時に左側の箸を取ってしまうと、右側の箸が使えず、いつまでたっても食事ができないことになる（画像は https://docs.oracle.com/cd/E19205-01/821-2500/gepdy/index.html より引用）。\n",
        "\n",
        "![](https://docs.oracle.com/cd/E19205-01/821-2500/images/figure2.gif)\n",
        "\n",
        "デッドロックを検出するには、タイムアウトを設定する。つまり、ロックの `acquire()` メソッド呼び出し時に `timeout` を設定し、メソッドの戻り値が `False` なら例外を送出する。\n",
        "\n",
        "``` python\n",
        "try:\n",
        "    acquired = lock1.acquire(timeout=3)\n",
        "    if not acquired:\n",
        "        raise TimeoutError(\"{}: Deadlock detected\".format(threading.current_thread().name))\n",
        "    # do something\n",
        "finally:\n",
        "    lock1.release()\n",
        "```\n",
        "\n",
        "ただし、ロック獲得にタイムアウトを設定する場合、同時にノンブロッキングには設定できないことに注意する。"
      ],
      "metadata": {
        "id": "QW5kpGJOkHIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 再入可能ロック ###"
      ],
      "metadata": {
        "id": "sna8rpih-6pF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "デッドロックは、同じスレッドで同じロックを複数回獲得しようとする場合にも発生する。\n",
        "\n",
        "たとえば、次のコードでは `worker()` 関数が再帰関数であり、呼び出すと引数 `times` を増やしながら再帰呼び出しが行われ、`times` が 3 以上になったら終了することを意図している。\n",
        "\n",
        "``` python\n",
        "import time\n",
        "import threading\n",
        "\n",
        "\n",
        "def worker(data, times, lock):\n",
        "    print(f\"{times=}\")\n",
        "    if times >= 3:\n",
        "        return None\n",
        "    else:\n",
        "        with lock:\n",
        "            n = data['n']\n",
        "            time.sleep(0.2)\n",
        "            data['n'] = n + 1\n",
        "            worker(data, times + 1, lock)\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    lock = threading.Lock()\n",
        "    thread = threading.Thread(target=worker, args=(data, 0, lock))\n",
        "    thread.start()\n",
        "    thread.join()\n",
        "    print(f\"{data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "ところが、このコードを実行すると、次のように出力されたまま先に進まない:\n",
        "\n",
        "``` text\n",
        "times=0\n",
        "times=1\n",
        "```\n",
        "\n",
        "1 回目の再帰呼び出しから先に進めないというデッドロックが起こる。これは、`worker()` の with 文の中でロックが解放されないまま再帰呼び出しがあり、そこでロックを獲得できず待機するからである。\n",
        "\n",
        "この場合は、次の関数により得られる**再入可能ロック**（reentrant lock）を使用すればデッドロックを回避できる:\n",
        "\n",
        "``` python\n",
        "threading.RLock()\n",
        "```\n",
        "\n",
        "通常のロックと再入可能ロックの違いは、以下の点だけである。\n",
        "\n",
        "  * いったんスレッドが再入可能ロックを獲得すると、同じスレッドはブロックされずにもう一度それを獲得できる。\n",
        "  * そのスレッドは獲得した回数だけ再入可能ロックを解放しなければならない。\n",
        "\n",
        "次のコードは、上記のコードを、再入可能ロックを使用するように変更したものである。"
      ],
      "metadata": {
        "id": "QEkZ6s-N-9M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def worker(data, times, lock):\n",
        "    print(f\"{times=}\")\n",
        "    if times >= 3:\n",
        "        return None\n",
        "    else:\n",
        "        with lock:\n",
        "            n = data['n']\n",
        "            time.sleep(0.2)\n",
        "            data['n'] = n + 1\n",
        "            worker(data, times + 1, lock)\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = {'n': 0}\n",
        "    lock = threading.RLock()\n",
        "    thread = threading.Thread(target=worker, args=(data, 0, lock))\n",
        "    thread.start()\n",
        "    thread.join()\n",
        "    print(f\"{data['n']=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29gotJ2DDdLC",
        "outputId": "2cef7433-a422-4ef0-8557-6d76090e5d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "times=0\n",
            "times=1\n",
            "times=2\n",
            "times=3\n",
            "data['n']=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### セマフォ ###"
      ],
      "metadata": {
        "id": "LGbJE-hiwObb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ミューテックスより緩く、最大〇個のスレッドが共有資源にアクセスして良いとする排他制御の方式を**セマフォ**（semaphore）という。セマフォは、内部に空き数を示すカウンターを持つ。\n",
        "\n",
        "セマフォでは直列化を実現できない。セマフォは、メモリ不足の回避やサーバーの負荷分散などの理由で、同時実行数に制限が必要な場合に使用される。\n",
        "\n",
        "`threading` は、2 種類のセマフォをサポートする。1 つは通常のセマフォであり、もう 1 つは**有限セマフォ**（bounded semaphore）である。これらはそれぞれ `threading.Semaphore` クラスと `threading.BoundedSemaphore` クラスで実装される。インスタンス化は次のとおり:\n",
        "\n",
        "``` python\n",
        "threading.Semaphore(value=1)\n",
        "threading.BoundedSemaphore(value=1)\n",
        "```\n",
        "\n",
        "`value` 引数は内部カウンターの初期値である。`value` を指定しない場合、デフォルトの値は 1 になる。セマフォは、ロックと同様に `acquire()` メソッドと `release()` メソッドを持ち、コンテキストマネージャーとして使用できる。\n",
        "\n",
        "`acquire()` メソッドを呼び出すとカンターが 1 つ減少し、`release()` メソッドを呼び出すとカウンタが 1 つ増加する。カウンターが 0 の場合に `acquire()` メソッドを呼び出すと、カウンターが 1 以上になるまで待機する。この動作は、`acquire()` メソッドの引数 `blocking` と `timeout` で変更できる。\n",
        "\n",
        "`release()` メソッドは引数 `n` として整数値を渡すことができ、内部カウンターを `n` だけ増加することもできる（`n` のデフォルトの値が 1 とされる）。通常のセマフォの `release()` メソッドの場合、何度呼び出してもカウンターは増加し続け初期値を上回ることができる。これに対して、有限セマフォの `release()` メソッドの場合、カウンターが初期値を上回ると `ValueError` 例外を送出する。\n",
        "\n",
        "`acquire()` メソッドと `release()` メソッドを直接使う代わりに with 文でセマフォを使う限り、セマフォの内部カウンターが初期値を上回ることは考えにくいのであるが、カウンターの上限を確実に初期値に制限したい場合は、有限セマフォを選択するとよい。\n",
        "\n",
        "次のコードは、Web サーバーから複数のファイルをダウンロードする処理をマルチスレッド化する例である。最大同時接続数を 2 とするために有限セマフォを利用している。"
      ],
      "metadata": {
        "id": "qLIfFIqHwPR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def download(url, semaphore):\n",
        "    with semaphore:\n",
        "        print(f\"{url} からのダウンロード開始\")\n",
        "        time.sleep(random.uniform(0.2, 1.0))  # ダウンロードの処理時間をシミュレート\n",
        "        print(f\"{url} からのダウンロード終了\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    semaphore = threading.BoundedSemaphore(2)\n",
        "    threads = [threading.Thread(target=download, args=(f\"url{i}\", semaphore)) for i in range(5)]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRIg5LAajexO",
        "outputId": "243e3764-895d-4b23-a569-c0ba9a1b14cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "url0 からのダウンロード開始\n",
            "url1 からのダウンロード開始\n",
            "url1 からのダウンロード終了\n",
            "url2 からのダウンロード開始\n",
            "url2 からのダウンロード終了\n",
            "url3 からのダウンロード開始\n",
            "url0 からのダウンロード終了\n",
            "url4 からのダウンロード開始\n",
            "url4 からのダウンロード終了\n",
            "url3 からのダウンロード終了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### イベントとスレッド間通信 ###"
      ],
      "metadata": {
        "id": "i9GDVVfxGrXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**イベント**は、特定の条件が満たされたことをスレッド間で**通知する**（notify）ために使用される。たとえば、あるタスクが完了したことを他のタスクに知らせたい場合に使用される。このようにスレッド間で通知が行われることを**スレッド間通信**と呼ぶ。\n",
        "\n",
        "イベントは内部にフラグを持ち、このフラグがセットされたりクリアされたりする。同期を取りたいスレッド間でイベントを共有し、あるスレッドにより内部フラグがセットされることで他のスレッドは通知を受ける。このようにスレッド間通信と言っても、その仕組みは単純で、各スレッドからアクセスできる変数（グローバル変数や引数など）を介して値を操作したり確認したりしているだけである。\n",
        "\n",
        "``` python\n",
        "threading.Event()\n",
        "```\n",
        "\n",
        "これは、内部フラグの値が `False` であるイベントオブジェクトを返す。イベントオブジェクトは、次のメソッドを持つ:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `set()` | 内部フラグの値を `True` にセットする | `None` |\n",
        "| `clear()` | 内部フラグの値を `False` にリセットする | `None` |\n",
        "| `wait(timeout=None)` | 内部フラグがセットされない間は待機する。内部フラグがセットされると待機を解除し、プログラムの実行を続ける。`timeout` に<br />浮動小数点数を指定した場合は、このメソッドは `timeout` 秒でタイムアウトする（プログラムの実行を続ける）。戻り値は、内部フ<br />ラグがセットされたために返された場合は `True`、`timeout` が指定されてタイムアウトした場合は `False` | `bool` |\n",
        "| `is_set()` | 内部フラグが `True` にセットされているとき `True` を返す | `bool` |\n",
        "\n",
        "`set()` でいったん内部フラグが `True` になると、スレッドが `wait()` を呼び出しても待機しなくなる。`clear()` で内部フラグをリセットすれば、`wait()` を呼び出したスレッドは待機するようになる。\n",
        "\n",
        "次のコードは、イベントの使用例である。`worker()` 関数が動くスレッドたちは、`wait()` を呼び出すと待機しイベントを監視する。`event_trigger()` 関数が動くスレッドが `set()` で内部フラグをセットすると、`worker()` 関数が動くスレッドたちは同時に開始される。"
      ],
      "metadata": {
        "id": "GzTtaPCfGsB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def worker(event):\n",
        "    event.wait()\n",
        "    print(f\"{threading.current_thread().name}: start\")\n",
        "    time.sleep(0.2)\n",
        "    print(f\"{threading.current_thread().name}: end\")\n",
        "\n",
        "\n",
        "def event_trigger(event):\n",
        "    print(f\"{threading.current_thread().name}: start\")\n",
        "    time.sleep(0.5)\n",
        "    print(f\"{threading.current_thread().name}: end\")\n",
        "    event.set()\n",
        "\n",
        "\n",
        "def main():\n",
        "    event = threading.Event()\n",
        "    threads = [\n",
        "        threading.Thread(target=worker, name=\"t1\", args=(event,)),\n",
        "        threading.Thread(target=worker, name=\"t2\", args=(event,)),\n",
        "        threading.Thread(target=event_trigger, name=\"t3\", args=(event,)),\n",
        "    ]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdiYN6JTDyu1",
        "outputId": "c1ea04e8-86bf-4517-9903-0b747ed3e759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t3: start\n",
            "t3: end\n",
            "t2: start\n",
            "t1: start\n",
            "t2: end\n",
            "t1: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "イベントは、あるスレッドの処理を完了させてから、その結果を利用して別のスレッドで処理を行いたい場合に便利である。ミューテックスではスレッドの順番を指定できないことに注意する。"
      ],
      "metadata": {
        "id": "mfqmXpj-CAmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### コンディション ###"
      ],
      "metadata": {
        "id": "Vd4PoNb0_thD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**コンディション**も、イベントと同様に特定の条件が満たされたときにスレッドの実行を再開するための同期プリミティブである。イベントと同様に `wait()` を呼び出したスレッドたちが待機し、通知を受けると起こされる。イベントと違って、コンディションは内部にロックを持つ。スレッドの実行再開は、ロック方式の排他制御が行われて直列化される。\n",
        "\n",
        "``` python\n",
        "threading.Condition(lock=None)\n",
        "```\n",
        "\n",
        "これはコンディションオブジェクトを返す。デフォルトでは、内部ロックとして再入可能ロックが新たに自動的に作成される。既存のロックをコンストラクタの引数として渡すこともでき、これにより複数のコンディションで同じロックを共有できる。\n",
        "\n",
        "コンディションオブジェクトは、次のメソッドを持つ:\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `acquire(*args)` | 内部ロックの `acquire()` メソッドを呼び出し、その戻り値を返す | `bool` |\n",
        "| `release()` | 内部ロックの `release()` メソッドを呼び出す | `None` |\n",
        "| `wait(timeout=None)` | 通知を受けるか、タイムアウトするまで待機する。このメソッドはいったんロックを解放し、一度スレッドが起こされると、再度ロック<br />を獲得して処理を戻す。<br />与えられた `timeout` が過ぎていなければ返り値は `True` となる。タイムアウトした場合には `False` を返す | `bool` |\n",
        "| `notify(n=1)` | 待機中スレッドのうち `n` 個のスレッドを起こす。`n` のデフォルト値は `1` | `None` |\n",
        "| `notify_all()` | 全ての待機中スレッドを起こす | `None` |\n",
        "\n",
        "コンディションは、ロックと同様にコンテキストマネージャーとして使用できる。\n",
        "\n",
        "`acquire()` と `release()` 以外のメソッドは、呼び出し側のスレッドがロックを獲得していないときに呼び出すと `RuntimeError` が送出される。\n",
        "\n",
        "次のコードは、イベントの使用例をコンディションで書き直した例である。"
      ],
      "metadata": {
        "id": "J3fP-vC0_vUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def worker(condition):\n",
        "    with condition:\n",
        "        condition.wait()\n",
        "        print(f\"{threading.current_thread().name}: start\")\n",
        "        time.sleep(0.2)\n",
        "        print(f\"{threading.current_thread().name}: end\")\n",
        "\n",
        "\n",
        "def event_trigger(condition):\n",
        "    with condition:\n",
        "        print(f\"{threading.current_thread().name}: start\")\n",
        "        time.sleep(0.5)\n",
        "        print(f\"{threading.current_thread().name}: end\")\n",
        "        condition.notify_all()\n",
        "\n",
        "\n",
        "def main():\n",
        "    condition = threading.Condition()\n",
        "    threads = [\n",
        "        threading.Thread(target=worker, name=\"t1\", args=(condition,)),\n",
        "        threading.Thread(target=worker, name=\"t2\", args=(condition,)),\n",
        "        threading.Thread(target=event_trigger, name=\"t3\", args=(condition,)),\n",
        "    ]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCAZ6fHOBsZp",
        "outputId": "aa736734-9e97-488b-ec63-53571bc99c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t3: start\n",
            "t3: end\n",
            "t2: start\n",
            "t2: end\n",
            "t1: start\n",
            "t1: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`t1` スレッドは、`worker()` 関数内の `with condition` でロックを獲得して `wait()` を呼び出すと、いったんロックを解放して待機する。`t2` スレッドも同様である。`t3` スレッドは、`event_trigger()` 関数内の `with condition` でロックを獲得すると、ロックを保持したまま処理を完了し、最後に `notify_all()` を呼び出す。これにより `t1` スレッドが起こされると、再度ロックを獲得して続きの処理を行う。`t2` スレッドも同様である。`t1` スレッドと `t2` スレッドがロックを伴って動作するため、直列化される。\n",
        "\n",
        "コンディションは、共有データを扱う場面での競合状態で、スレッドの順序付けと直列化を併用したい場合に便利である。"
      ],
      "metadata": {
        "id": "ewOweOFtVLna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### バリア ###"
      ],
      "metadata": {
        "id": "Z3SN-DkcCyjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` python\n",
        "threading.Barrier(parties, action=None, timeout=None)\n",
        "```\n",
        "\n",
        "これはバリアオブジェクトを返す。**バリア**は、指定された数のスレッドが到達するまで待つような地点を設定する機能を提供する。\n",
        "\n",
        "具体的には、コンストラクタに渡される `parties` がスレッドの必要数であり、バリアオブジェクトの `wait()` メソッドでバリアの地点が設定される。つまり、`wait()` を呼んだ地点でスレッドが待機し、`parties` 個のスレッドが `wait()` を呼ぶと、それらは同時にすべて解放される。呼び出し可能オブジェクトが `action` としてコンストラクタに渡されていれば、スレッドが解放される時にそのうちの 1 つによって呼ばれる。\n",
        "\n",
        "実のところ、バリアは内部にコンディションを持ち、スレッドの待ち合わせと解放がコンディションを使ったスレッド間通信により実現されている。このため、必要な数のスレッドがバリアの地点に到達しないと、デッドロックが発生する。デッドロックを回避するには、タイムアウトを使用する必要がある。`wait()` は `timeout` 引数を取り、それに浮動小数点数を与えると `timeout` 秒後にタイムアウトし、バリアが破壊される。スレッドが待っている間にバリアが破壊された場合、`wait()` メソッドは `threading.BrokenBarrierError` 例外を送出する。コンストラクタの `timeout` 引数でデフォルトのタイムアウト時間を指定できる。\n",
        "\n",
        "次のコードはバリアの使用例である。"
      ],
      "metadata": {
        "id": "h78fnRMFCzbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def report():\n",
        "    print(\"{}: passed through the barrier\".format(threading.current_thread().name))\n",
        "\n",
        "\n",
        "def worker(barrier):\n",
        "    time.sleep(random.uniform(0.2, 1.0))\n",
        "    print(f\"{threading.current_thread().name}: start\")\n",
        "    try:\n",
        "        barrier.wait(timeout=1.0)\n",
        "    except threading.BrokenBarrierError:\n",
        "        print(f\"{threading.current_thread().name}: TIMEOUT\")\n",
        "    else:\n",
        "        print(f\"{threading.current_thread().name}: end\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    barrier = threading.Barrier(2, action=report)\n",
        "    threads = [threading.Thread(target=worker, name=f\"t{i}\", args=(barrier,)) for i in range(5)]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7WMrEU-ljl0",
        "outputId": "8313bff7-fbc0-49af-e45a-de0c64361c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t4: start\n",
            "t2: start\n",
            "t2: passed through the barrier\n",
            "t2: end\n",
            "t4: end\n",
            "t1: start\n",
            "t3: start\n",
            "t3: passed through the barrier\n",
            "t3: end\n",
            "t1: end\n",
            "t0: start\n",
            "t0: TIMEOUT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### スレッドローカルデータ ###"
      ],
      "metadata": {
        "id": "7zpi29s_qph8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`threading.local` は、**スレッドローカルデータ**と呼ばれ、スレッド間で共有するオブジェクトでありながら、属性値は共有されないという特殊なオブジェクトの型である。`threading.local` の使用では、競合状態が起こらない。\n",
        "\n",
        "スレッドローカルデータの例としては、各スレッドの動作を記録するログが挙げられる。ログには次のようなデータが記録される。\n",
        "\n",
        "  * スレッド名\n",
        "  * セッション ID\n",
        "  * リクエスト ID\n",
        "  * エラー情報\n",
        "\n",
        "これらはスレッドに固有であり、スレッドの存続期間に渡って使用されるデータであるが、スレッドの実行に必要ではないため、スレッドで実行する関数の引数として渡したり、戻り値や例外メッセージとして呼び出し元に返すのは面倒である。この場合の一般的な解決策は、スレッドローカルデータを使用することである。\n",
        "\n",
        "次のコードでは、`threading.local` を使用する例である。`local` は `threading.local` のインスタンスで、`worke` スレッドで `x` 属性が変更されるにもかかわらず、メインスレッドでは `x` 属性の変更が共有されない。"
      ],
      "metadata": {
        "id": "yqj7nAZkqqMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "local = threading.local()\n",
        "\n",
        "\n",
        "def worker():\n",
        "    local.x = 1\n",
        "    print(f\"{threading.current_thread().name}: {local.x=}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    local.x = 0\n",
        "\n",
        "    thread = threading.Thread(target=worker, name=\"worker\")\n",
        "    thread.start()\n",
        "    thread.join()\n",
        "\n",
        "    print(f\"{threading.current_thread().name}: {local.x=}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3rE84IX-esX",
        "outputId": "9336ea33-4729-4356-a0c1-4c813ff14591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worker: local.x=1\n",
            "MainThread: local.x=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### スレッドのカスタマイズ ###"
      ],
      "metadata": {
        "id": "qCfXViUQggNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`threading.Thread` クラスを継承して、`run()` メソッドをオーバーライドしたサブクラスを利用することができる。もとの `run()` メソッドは、インスタンス化の際に `target` が渡されていれば、それを実行するだけである。`run()` メソッドをオーバーライドすることで、スレッドの動作をカスタマイズできる。\n",
        "\n",
        "クラス継承を使用したカスタマイズの良い例が、`threading.Timer` である。`threading.Timer` は、`interval` 秒後に実行するスレッドである。次のコードは、その定義の要約である。\n",
        "\n",
        "``` python\n",
        "class Timer(Thread):\n",
        "    def __init__(self, interval, function, args=None, kwargs=None):\n",
        "        Thread.__init__(self)\n",
        "        self.interval = interval\n",
        "        self.function = function\n",
        "        self.args = args if args is not None else []\n",
        "        self.kwargs = kwargs if kwargs is not None else {}\n",
        "        self.finished = Event()\n",
        "\n",
        "    def cancel(self):\n",
        "        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n",
        "        self.finished.set()\n",
        "\n",
        "    def run(self):\n",
        "        self.finished.wait(self.interval)\n",
        "        if not self.finished.is_set():\n",
        "            self.function(*self.args, **self.kwargs)\n",
        "        self.finished.set()\n",
        "```\n",
        "\n",
        "`threading.Timer` は、内部にイベントオブジェクト `finished` を持ち、`run()` メソッドが `wait()` でタイムアウトすると `function` を実行するようにオーバーライドされている。`interval` 秒経過する前であれば中止できる `cancel()` メソッドも定義されている。\n",
        "\n",
        "たとえば、次のコードを実行すると、30 秒後に `'hello, world'` が出力される。\n",
        "\n",
        "``` python\n",
        "def hello():\n",
        "    print(\"hello, world\")\n",
        "\n",
        "t = Timer(30.0, hello)\n",
        "t.start()\n",
        "```"
      ],
      "metadata": {
        "id": "XVeYccDNghD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "queue\n",
        "-----"
      ],
      "metadata": {
        "id": "KJ4DP92nPWYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準ライブラリの `queue` モジュールは、データ構造とコンディションを組み合わせて、スレッド間で共有するデータ構造から次々とアイテムを取り出し、アイテムに対する処理をロックを伴って行うことをサポートする。これは、複数のスレッドの間でデータを安全に交換しなければならないときのマルチスレッドプログラミングで特に有益である。\n",
        "\n",
        "内部に持つデータ構造の種類により、以下のクラスが提供される。\n",
        "\n",
        "  * `queue.Queue`: FIFO のデータ構造、すなわちキュー（`collections.deque` で実装される）\n",
        "  * `queue.LifoQueue`: LIFO のデータ構造、すなわちスタック（`collections.deque` で実装される）\n",
        "  * `queue.PriorityQueue`: 優先度付きキュー（`heapq` の関数で実装される）\n",
        "\n",
        "下 2 つのクラスは `queue.Queue` の派生クラスであり、データ構造に関する内部メソッドをオーバライドしている。3 つのクラスのコンストラクタ引数とメソッドは共通している。\n",
        "\n",
        "``` python\n",
        "queue.Queue(maxsize=0)\n",
        "```\n",
        "\n",
        "コンストラクタの引数 `maxsize` は、キューに入れられるアイテム数の上限を設定する整数。`maxsize` が 0 以下の場合は、キューの大きさは無限となる。\n",
        "\n",
        "`queue.Queue` は、キューに入れられたアイテムで処理が完了していないものを内部でカウントする。このカウントを「未完了タスクのカウント」と呼ぶ。アイテムをキューに入れるとき、「未完了タスクのカウント」はインクリメントされる。アイテムの処理が完了したら、「未完了タスクのカウント」をデクリメントできる。\n",
        "\n",
        "主なメソッドは次のとおり。\n",
        "\n",
        "| メソッド | 機能 | 戻り値 |\n",
        "|:---|:---|:---|\n",
        "| `put(item, block=True,`<br />` timeout=None)` | `item` をキューに挿入し、「未完了タスクのカウント」をインクリメントする。キューの上限が設定されていて上限に達していた<br />場合、`block` が `True`（デフォルト）なら挿入処理はキューのアイテムが取り出されて空きが出るまでブロックされる。ただし、<br />`timeout` に浮動小数点数を指定していれば、空きが出ないまま `timeout` 秒経過した時に `queue.Full` 例外を送出する。<br />`block` が `False` なら直ちに `queue.Full` 例外を送出する（この場合 `timeout` は無視される） | `None` |\n",
        "| `put_nowait(item)` | `put(item, block=False)` と等価 | `None` |\n",
        "| `get(block=True,`<br />` timeout=None)` | キューからロックを伴ってアイテムを取り出す。通知を受けるか、タイムアウトするまで待機する。キューが空の場合は、`block`<br /> が `True`（デフォルト）ならアイテムが入るまでブロックされ、`block` が `False` なら直ちに `queue.Empty` 例外を送出する（こ<br />の場合 `timeout` は無視される） | アイテム |\n",
        "| `get_nowait()` | `get(block=False)` と等価 | アイテム |\n",
        "| `empty()` | キューが空の場合は `True` を返し、そうでなければ `False` を返す | `bool` |\n",
        "| `full()` | キューが一杯の場合は `True` を返し、そうでなければ `False` を返す | `bool` |\n",
        "| `task_done()` | 内部コンディションの `notify_all()` を呼び出し、`get()` で待機中の全てのスレッドを起こす。また、「未完了タスクのカウン<br />ト」をデクリメントする。この結果 0 未満になった場合（つまりキューにある要素より多く呼び出された場合） `ValueError` 例<br />外が発生する | `None` |\n",
        "| `join()` | 「未完了タスクのカウント」が 0 になるまで待機する | `None` |\n",
        "\n",
        "`join()` はキューにあるすべてのアイテムが取り出されて処理されるまで待機したい場合に使用する。この場合、アイテムの取り出しに使われた `get()` の後に必ず `task_done()` を呼び出すようにしないと、いつまでたっても「未完了タスクのカウント」が 0 にならず、`join()` で待機し続けることになるので注意。\n",
        "\n",
        "次のコードは、5 つのアイテム（`1` から `5` までの整数）の処理を 2 つのスレッドで同時に行うためにキューを使用する例である。各スレッドが動かす `worker()` 関数は、while ループにより、キューからアイテムを取り出し処理が終わっても終了せず、キューが空になるまでアイテムの処理を繰り返す。このように、ある一定数のスレッドをあらかじめ作成し、必要に応じてタスクを割り振ったり、使い回したりする仕組みを**スレッドプール**（thread pool）と呼ぶ。"
      ],
      "metadata": {
        "id": "VoYjdEbiNtE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def worker(q):\n",
        "    while not q.empty():\n",
        "        try:\n",
        "            item = q.get_nowait()\n",
        "        except queue.Empty:\n",
        "            break\n",
        "        else:\n",
        "            print(f\"{threading.current_thread().name}: Working on {item}\")\n",
        "            time.sleep(item * 0.1)\n",
        "            print(f\"{threading.current_thread().name}: Finished {item}\")\n",
        "            q.task_done()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Queue を設定\n",
        "    q = queue.Queue()\n",
        "    for i in range(1, 6):\n",
        "        q.put(i)\n",
        "\n",
        "    # スレッドプールを設定（2 つのスレッドからなる）\n",
        "    threads = []\n",
        "    for i in range(2):\n",
        "        thread = threading.Thread(target=worker, name=f\"t{i}\", args=(q,))\n",
        "        threads.append(thread)\n",
        "\n",
        "    # スレッドの開始\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "\n",
        "    # キューが空になるまで待機\n",
        "    q.join()\n",
        "    print(\"全てのタスクが完了した\")\n",
        "\n",
        "    # 終了を待機\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "344UhHMnNxDz",
        "outputId": "5ecc8031-c906-4e86-f608-24e6c14d6a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t0: Working on 1\n",
            "t1: Working on 2\n",
            "t0: Finished 1\n",
            "t0: Working on 3\n",
            "t1: Finished 2\n",
            "t1: Working on 4\n",
            "t0: Finished 3\n",
            "t0: Working on 5\n",
            "t1: Finished 4\n",
            "t0: Finished 5\n",
            "全てのタスクが完了した\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`worker()` 関数では while の条件でキューが空でないことを確認しているが、`get_nowait()` でキューが空の場合の例外処理をしている。確認後にキューの状態が他のスレッドにより変更される可能性があるからである。`get_nowait()` はキューが空の場合に直ちに `queue.Empty` 例外を送出する。`queue.Empty` 例外を捕捉したら while ループを停止して関数を終了する（else 節は実行されない）。\n",
        "\n",
        "実行結果から、各タスクが処理の完了したスレッドに次々と割り振られ、各スレッドではタスク処理が直列化されることがわかる。"
      ],
      "metadata": {
        "id": "5q7WL_a0Ahyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "スレッドセーフ\n",
        "--------------"
      ],
      "metadata": {
        "id": "qZ93oYUguoB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチスレッドでデータ競合による未定義動作を引き起こしたり、競合状態による意図しない動作を引き起こしたりせず、デッドロックなどの問題も起きないプログラムは**スレッドセーフ**（thread-safe）であるという。\n",
        "\n",
        "以下は、Python でのマルチスレッドとスレッドセーフなコーディングのためのベストプラクティスである。\n",
        "\n",
        "  * **マルチスレッドを使わない**  \n",
        "マルチスレッドはプロセス内の制御フローが難解になる。メモリ共有のため、1 つのスレッドの問題がプロセス全体に影響を与える可能性がある。同期やロックを忘れたり、デッドロックが起こるというミスを防げない。再現性の低いバグを見つける作業は難しい。CPython 特有の問題として、CPU バウンドな処理ではかえって遅くなる。マルチプロセスを使うべきである。\n",
        "  * **共有リソースを最小化する**  \n",
        "あえてマルチスレッドを選択する場合（マルチプロセスでのオーバーヘッドが許容できないなど）、共有データを使用せず、同期やロックを考えなくて済むようにすること。スレッドローカルデータを活用すること。\n",
        "  * **不変オブジェクトを利用する**  \n",
        "値オブジェクトは上記の例外である。値オブジェクトは不変だから、自然とスレッドセーフである。\n",
        "  * **ロックの範囲を最小化する**  \n",
        "どうしても共有データを使わなければならない場合、ロックを獲得している間は、できるだけ少ない操作を行い、他のスレッドが待たされる時間を短縮すること。\n",
        "  * **タイムアウトを使用する**  \n",
        "`acquire()` と `wait()` にタイムアウトを設定することで、デッドロックが発生した場合でも、スレッドが適切に解放されるようになる。"
      ],
      "metadata": {
        "id": "FZgRDVvgupFu"
      }
    }
  ]
}